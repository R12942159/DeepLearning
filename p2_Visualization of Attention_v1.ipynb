{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/NTU_DLCV/blob/Hw3/p2_Visualization%20of%20Attention_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### load model weights"
      ],
      "metadata": {
        "id": "T3ULd3iIh8Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1-4LS5WGhXkrkkThaEzGBCFVUZz8mZqa8 -O trainable_weights # large epoch4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_ENijHeh_7D",
        "outputId": "0ef511cf-d8b8-4536-b5c0-1513de93b738"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-4LS5WGhXkrkkThaEzGBCFVUZz8mZqa8\n",
            "To: /content/trainable_weights\n",
            "100% 117M/117M [00:02<00:00, 45.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TmhsvrhiElx",
        "outputId": "a3f91773-ad4c-410a-815d-c1ae5845447c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "Xb59e3Ej2GPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import timm\n",
        "import json\n",
        "import torch\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as tr\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from torch import nn, Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms.functional import resize"
      ],
      "metadata": {
        "id": "SBi1aSqPhMuD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eg4VzCElm83",
        "outputId": "95c5b413-8b73-438f-a051-b9bc8ad126fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download dataset and unzip zip file."
      ],
      "metadata": {
        "id": "Q22ZX1_VhKiK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DG6GOxEHD9l"
      },
      "outputs": [],
      "source": [
        "!gdown 1SUiRrG6zQVtyrVSVh9hOBq5_fX-oV2Lh -O hw3_data.zip # 11rP6KmR5Qwjhx0rfag0b5TZGBTRuPtQR\n",
        "!unzip /content/hw3_data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizer ('<|endoftext|>', 50256) -> 250dim"
      ],
      "metadata": {
        "id": "sIMyluP4OcRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BPETokenizer:\n",
        "\n",
        "    def __init__(self, encoder_file, vocab_file):\n",
        "        with open(encoder_file, 'r', encoding='utf-8') as f:\n",
        "            self.encoder = json.load(f)\n",
        "        self.decoder = {v:k for k,v in self.encoder.items()}\n",
        "        with open(vocab_file, 'r', encoding='utf-8') as f:\n",
        "            vocab = f.read().split('\\n')[1:-1]\n",
        "        self.bpe_ranks = {tuple(line.split()): i for i, line in enumerate(vocab)}\n",
        "        assert len(self.encoder) == 50257 and len(self.bpe_ranks) == 50000 # len(self.bpe_ranks) == 50000\n",
        "        bs = list(range(33, 127)) + list(range(161, 256))\n",
        "        xs = list(range(0, 33)) + list(range(127, 161))\n",
        "        cs = bs[:] + [2**8 + i for i in range(len(xs))]\n",
        "        self.byte_encoder = dict(zip(bs + xs, [chr(n) for n in cs]))\n",
        "        self.byte_decoder = {v:k for k, v in self.byte_encoder.items()}\n",
        "\n",
        "    def encode(self, text, allowed_special=None):\n",
        "        tokens = re.findall(r\"\"\"<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d| ?\"\"\" +\n",
        "                            r\"\"\"\\w+| ?\\d+| ?[^\\s\\w\\d]+|\\s+(?!\\S)|\\s+\"\"\", text, re.UNICODE)\n",
        "        def translate(token):\n",
        "            if token == '<|endoftext|>':\n",
        "                assert allowed_special and token in allowed_special\n",
        "                return [token]\n",
        "            word = tuple(''.join(self.byte_encoder[byte] for byte in token.encode('utf-8')))\n",
        "            while len(word) != 1:\n",
        "                pairs = set((word[i], word[i+1]) for i in range(len(word)-1))\n",
        "                bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
        "                if bigram not in self.bpe_ranks:\n",
        "                    break\n",
        "                a, b = bigram\n",
        "                new_word = []\n",
        "                i = 0\n",
        "                while i < len(word):\n",
        "                    j = word.index(a, i) if a in word[i:] else len(word)\n",
        "                    new_word.extend(word[i:j])\n",
        "                    i = j\n",
        "                    if i < len(word):\n",
        "                        j = 2 if i < len(word)-1 and word[i] == a and word[i+1] == b else 1\n",
        "                        new_word.append(a+b if j == 2 else word[i])\n",
        "                        i += j\n",
        "                word = tuple(new_word)\n",
        "            return word\n",
        "        return [self.encoder[_] for token in tokens for _ in translate(token)]\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        tokens = [self.decoder[token] for token in tokens]\n",
        "        buffer = bytearray([self.byte_decoder[c] for c in ''.join(tokens)])\n",
        "        return buffer.decode('utf-8', errors='replace')"
      ],
      "metadata": {
        "id": "gjc6poP1OdBM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = BPETokenizer('/content/encoder.json', '/content/vocab.bpe')"
      ],
      "metadata": {
        "id": "6aeCuLyJOmhP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define function"
      ],
      "metadata": {
        "id": "L0JYrzNqE0mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def json_load(json_path: str):\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    return data"
      ],
      "metadata": {
        "id": "z5xRsOP3h96o"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caption_with_id(json_path: str) -> list:\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        json_data = json.load(file)\n",
        "    data = [{'caption': row['caption'], 'image_id': row['image_id']} for row in json_data['annotations']]\n",
        "    return data"
      ],
      "metadata": {
        "id": "vVR-onWwmbCI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id2file_name(json_path: str) -> dict:\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        json_data = json.load(file)\n",
        "    data = {row['id']: row['file_name'] for row in json_data['images']}\n",
        "    return data"
      ],
      "metadata": {
        "id": "rWW6y2Q1o_t-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Dataset"
      ],
      "metadata": {
        "id": "7TWHXZgugWOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImgDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root: str, transform) -> None:\n",
        "        self.transform = transform\n",
        "        self.img_path = [i for i in Path(root).glob(\"*.jpg\")]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.img_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.img_path[idx]).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        return img, os.path.splitext(self.img_path[idx].name)[0]"
      ],
      "metadata": {
        "id": "lYoLLeI3gZvS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Dataloader"
      ],
      "metadata": {
        "id": "vMk7sUiwHEPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_ds = ImgDataset(\n",
        "    root='/content/hw3_data/p4_data',\n",
        "    transform=tr.Compose([\n",
        "        tr.Resize(224),\n",
        "        tr.CenterCrop(224),\n",
        "        tr.ToTensor(),\n",
        "        tr.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        ")\n",
        "\n",
        "img_loader = DataLoader(\n",
        "    img_ds,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        ")"
      ],
      "metadata": {
        "id": "MMGD07vrHGiB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Config"
      ],
      "metadata": {
        "id": "Fx9an6CwEx-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "\n",
        "    def __init__(self, checkpoint=None):\n",
        "        self.n_layer = 12\n",
        "        self.n_head = 12\n",
        "        self.n_embd = 768\n",
        "        self.vocab_size = 50257\n",
        "        self.block_size = 1024\n",
        "        self.checkpoint = checkpoint"
      ],
      "metadata": {
        "id": "x39qAcvyEzgi"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = Config(checkpoint='/content/hw3_data/p2_data/decoder_model.bin')"
      ],
      "metadata": {
        "id": "lLwivdnDE5eq"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### decoder"
      ],
      "metadata": {
        "id": "w1QQ3sdc8GRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.c_attn = nn.Linear(cfg.n_embd, 3 * cfg.n_embd)\n",
        "        self.c_proj = nn.Linear(cfg.n_embd, cfg.n_embd)\n",
        "        self.n_head = cfg.n_head\n",
        "        self.n_embd = cfg.n_embd\n",
        "        size = cfg.block_size\n",
        "        self.register_buffer('bias', torch.tril(torch.ones(size, size)).view(1, 1, size, size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch, context, embedding\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        return self.c_proj((att @ v).transpose(1, 2).contiguous().view(B, T, C))\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.multihead_attn = nn.MultiheadAttention(cfg.n_embd, cfg.n_head, batch_first=True)\n",
        "\n",
        "    def forward(self, query, encoder_out):\n",
        "        \"\"\"\n",
        "        Q is the source from the decoder, K, V are the sources from the encoder.\n",
        "        Q: (N, L, Eq), where L is the target embedding dim, Eq is embed_dim and batch_first=True.\n",
        "        {K, V}: (N, L, E{k,v}), where L is the source embedding dim, E{k,v} is {k,v}_dim and batch_first=True.\n",
        "        \"\"\"\n",
        "        attn_output, attn_output_weights = self.multihead_attn(query, encoder_out, encoder_out)\n",
        "        return attn_output, attn_output_weights\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(cfg.n_embd)\n",
        "        self.ln_2 = nn.LayerNorm(cfg.n_embd) # add\n",
        "        self.ln_3 = nn.LayerNorm(cfg.n_embd)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.crs_attn = CrossAttention(cfg) # add\n",
        "        self.mlp = nn.Sequential(collections.OrderedDict([\n",
        "            ('c_fc', nn.Linear(cfg.n_embd, 4 * cfg.n_embd)),\n",
        "            ('act', nn.GELU(approximate='tanh')),\n",
        "            ('c_proj', nn.Linear(4 * cfg.n_embd, cfg.n_embd))\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x, encoder_out) -> Tensor: # add\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        cross_x, weights = self.crs_attn(self.ln_2(x), self.ln_2(encoder_out)) # add\n",
        "        x = cross_x + x\n",
        "        x = x + self.mlp(self.ln_3(x))\n",
        "        return x, weights\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.block_size = cfg.block_size\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(cfg.vocab_size, cfg.n_embd), # 文字投影\n",
        "            wpe = nn.Embedding(cfg.block_size, cfg.n_embd), # position\n",
        "            h = nn.Sequential(*[Block(cfg) for _ in range(cfg.n_layer)]), # Nx\n",
        "            ln_f = nn.LayerNorm(cfg.n_embd)\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(cfg.n_embd, cfg.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "        # timm's ViT encoder (vit_base_patch16_224_in21k, , vit_huge_patch14_224_in21k)\n",
        "        self.encoder = timm.create_model('vit_large_patch16_224_in21k', pretrained=True)\n",
        "        self.linear = nn.Linear(1024, cfg.n_embd) # [16, 197, 1024]\n",
        "        # load checkpoint\n",
        "        if self.cfg.checkpoint is not None:\n",
        "            state_dict = torch.load(self.cfg.checkpoint)\n",
        "            transposed = [ '.c_attn.weight', '.c_fc.weight', '.c_proj.weight' ]\n",
        "            for key, value in state_dict.items():\n",
        "                if any(key.endswith(w) for w in transposed):\n",
        "                    state_dict[key] = value.t()\n",
        "            self.transformer.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    def forward(self, x: Tensor, img: Tensor) -> Tensor: # add\n",
        "        x = torch.narrow(x, 1, 0, min(x.size(1), self.block_size))\n",
        "        pos = torch.arange(x.size()[1], dtype=torch.long, device=x.device).unsqueeze(0)\n",
        "        x = self.transformer.wte(x) + self.transformer.wpe(pos)\n",
        "        with torch.no_grad():\n",
        "            encoder_out = self.encoder.forward_features(img)\n",
        "        for block in self.transformer.h:\n",
        "            x, weights = block(x, self.linear(encoder_out))\n",
        "        x = self.lm_head(self.transformer.ln_f(x)) # add\n",
        "        return x, weights"
      ],
      "metadata": {
        "id": "TYyI157L8JB7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of Attention in Image Captioning"
      ],
      "metadata": {
        "id": "K4qEtiUZcjqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for img, file_name in img_loader:\n",
        "    print(img.size())\n",
        "    break"
      ],
      "metadata": {
        "id": "tAncSFVOPlBV",
        "outputId": "03ad8243-e278-4cba-a6c8-138fc96def4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Decoder(cfg).to(device)\n",
        "model.load_state_dict(torch.load(f'/content/trainable_weights', map_location=device), strict=False)"
      ],
      "metadata": {
        "id": "2e0KXMqQhCPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_dict = {}\n",
        "for img, file_name in tqdm(img_loader):\n",
        "\n",
        "    img = img.to(device)\n",
        "    start_token = torch.tensor([[50256]]).to(device)\n",
        "\n",
        "    for i in tqdm(range(250)):\n",
        "        with torch.no_grad():\n",
        "            pred, weights = model(start_token, img)\n",
        "        out_token = pred.argmax(dim=2)[0][-1]\n",
        "        start_token = torch.cat((start_token, out_token.unsqueeze(0).unsqueeze(0)), dim=1)\n",
        "        end_token = torch.sum(start_token[0] == 50256).item()\n",
        "        if end_token == 2:\n",
        "            pred_token = start_token[start_token != 50256]\n",
        "            pred_token = pred_token.tolist()\n",
        "            pred_caption = encoding.decode(pred_token)\n",
        "            break\n",
        "    # evaluation_dict[file_name[0]] = pred_caption\n",
        "\n",
        "    # visualization\n",
        "    token = re.findall(r'\\b\\w+\\b|[.,]', pred_caption)\n",
        "    nrow = (len(token) + 2) // 5 if (len(token) + 2) % 5 == 0 else (len(token) + 2) // 5 + 1\n",
        "    fig, ax = plt.subplots(ncols=5, nrows=nrow, figsize=(16, 8))\n",
        "\n",
        "    image = Image.open(os.path.join('/content/hw3_data/p4_data', file_name[0]+'.jpg')).convert('RGB')\n",
        "    ax[0][0].imshow(image)\n",
        "    ax[0][0].set_title('<|endoftext|>')\n",
        "    ax[0][0].axis('off')\n",
        "\n",
        "    for i, idx in enumerate(token):\n",
        "        attn_vector = weights[:, i, 1:]\n",
        "        heat_map = torch.reshape(attn_vector, (14,14))\n",
        "        heat_map -= torch.min(heat_map)\n",
        "        heat_map /= torch.max(heat_map)\n",
        "        heat_map = resize(heat_map.unsqueeze(0), [640,640]).squeeze(0).detach().cpu()\n",
        "        heat_map = np.uint8(heat_map * 255)\n",
        "\n",
        "        ax[(i+1)//5][(i+1)%5].imshow(image)\n",
        "        ax[(i+1)//5][(i+1)%5].set_title(idx)\n",
        "        ax[(i+1)//5][(i+1)%5].imshow(heat_map, alpha=0.7, cmap='jet')\n",
        "        ax[(i+1)//5][(i+1)%5].axis('off')\n",
        "\n",
        "    attn_vector = weights[:, -1, 1:]\n",
        "    heat_map = torch.reshape(attn_vector, (14,14))\n",
        "    heat_map -= torch.min(heat_map)\n",
        "    heat_map /= torch.max(heat_map)\n",
        "    heat_map = resize(heat_map.unsqueeze(0), [640,640]).squeeze(0).detach().cpu()\n",
        "    heat_map = np.uint8(heat_map * 255)\n",
        "\n",
        "    ax[nrow - 1][(len(token) + 2) % 5 - 1].imshow(image)\n",
        "    ax[nrow - 1][(len(token) + 2) % 5 - 1].set_title('<|endoftext|>')\n",
        "    ax[nrow - 1][(len(token) + 2) % 5 - 1].imshow(heat_map, alpha=0.7, cmap='jet')\n",
        "    ax[nrow - 1][(len(token) + 2) % 5 - 1].axis('off')\n",
        "\n",
        "    if (len(token) + 2) % 5 != 5:\n",
        "        for i in range(4, (len(token) + 2) % 5 - 1, -1):\n",
        "            ax[nrow - 1][i].axis('off')\n",
        "    else:\n",
        "        pass\n",
        "    plt.savefig(os.path.join('/content/drive/MyDrive/NTU_DLCV/Hw3/p3_img_out/p3_img_top1', file_name[0]))"
      ],
      "metadata": {
        "id": "UNewXUlkhKcG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f4f8184c-1534-4e77-bca2-721c8c7f94b2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/250 [00:04<19:17,  4.65s/it]\u001b[A\n",
            "  1%|          | 2/250 [00:08<16:26,  3.98s/it]\u001b[A\n",
            "  1%|          | 3/250 [00:11<14:47,  3.59s/it]\u001b[A\n",
            "  2%|▏         | 4/250 [00:14<13:52,  3.38s/it]\u001b[A\n",
            "  2%|▏         | 5/250 [00:18<14:31,  3.56s/it]\u001b[A\n",
            "  2%|▏         | 6/250 [00:22<16:02,  3.95s/it]\u001b[A\n",
            "  3%|▎         | 7/250 [00:26<15:37,  3.86s/it]\u001b[A\n",
            "  3%|▎         | 8/250 [00:29<14:34,  3.62s/it]\u001b[A\n",
            "  4%|▎         | 9/250 [00:32<13:54,  3.46s/it]\u001b[A\n",
            "  4%|▍         | 10/250 [00:39<17:38,  4.41s/it]\u001b[A\n",
            "  4%|▍         | 11/250 [00:43<17:31,  4.40s/it]\u001b[A\n",
            "  5%|▍         | 12/250 [00:46<15:53,  4.01s/it]\u001b[A\n",
            "  5%|▌         | 13/250 [00:49<14:45,  3.74s/it]\u001b[A\n",
            "  6%|▌         | 14/250 [00:53<13:55,  3.54s/it]\u001b[A\n",
            "  6%|▌         | 15/250 [00:57<15:11,  3.88s/it]\u001b[A\n",
            "  6%|▋         | 16/250 [01:02<15:44,  4.04s/it]\u001b[A\n",
            "  7%|▋         | 17/250 [01:05<14:35,  3.76s/it]\u001b[A\n",
            "  7%|▋         | 18/250 [01:08<13:46,  3.56s/it]\u001b[A\n",
            "  8%|▊         | 19/250 [01:12<14:16,  3.71s/it]\u001b[A\n",
            "  8%|▊         | 20/250 [01:17<15:23,  4.01s/it]\u001b[A\n",
            "  8%|▊         | 21/250 [01:21<15:21,  4.03s/it]\u001b[A\n",
            "  9%|▉         | 22/250 [01:24<14:17,  3.76s/it]\u001b[A\n",
            "  9%|▉         | 23/250 [01:27<13:31,  3.58s/it]\u001b[A\n",
            " 10%|▉         | 24/250 [01:31<13:27,  3.57s/it]\u001b[A\n",
            " 10%|█         | 25/250 [01:35<14:46,  3.94s/it]\u001b[A\n",
            " 10%|█         | 26/250 [01:39<14:42,  3.94s/it]\u001b[A\n",
            " 11%|█         | 27/250 [01:42<13:45,  3.70s/it]\u001b[A\n",
            " 11%|█         | 28/250 [01:46<13:06,  3.54s/it]\u001b[A\n",
            " 12%|█▏        | 29/250 [01:49<13:19,  3.62s/it]\u001b[A\n",
            " 12%|█▏        | 30/250 [01:54<14:38,  3.99s/it]\u001b[A\n",
            " 12%|█▏        | 31/250 [01:58<14:17,  3.92s/it]\u001b[A\n",
            " 13%|█▎        | 32/250 [02:02<14:34,  4.01s/it]\u001b[A\n",
            " 13%|█▎        | 33/250 [02:05<13:43,  3.79s/it]\u001b[A\n",
            " 14%|█▎        | 34/250 [02:10<14:39,  4.07s/it]\u001b[A\n",
            " 14%|█▍        | 35/250 [02:15<15:19,  4.28s/it]\u001b[A\n",
            " 14%|█▍        | 36/250 [02:18<14:13,  3.99s/it]\u001b[A\n",
            " 15%|█▍        | 37/250 [02:22<13:23,  3.77s/it]\u001b[A\n",
            " 15%|█▌        | 38/250 [02:25<13:00,  3.68s/it]\u001b[A\n",
            " 16%|█▌        | 39/250 [02:30<14:19,  4.07s/it]\u001b[A\n",
            " 16%|█▌        | 40/250 [02:34<14:27,  4.13s/it]\u001b[A\n",
            " 16%|█▋        | 41/250 [02:38<13:32,  3.89s/it]\u001b[A\n",
            " 17%|█▋        | 42/250 [02:41<12:49,  3.70s/it]\u001b[A\n",
            " 17%|█▋        | 43/250 [02:45<12:54,  3.74s/it]\u001b[A\n",
            " 18%|█▊        | 44/250 [02:50<14:13,  4.14s/it]\u001b[A\n",
            " 18%|█▊        | 45/250 [02:54<13:52,  4.06s/it]\u001b[A\n",
            " 18%|█▊        | 46/250 [02:57<13:02,  3.84s/it]\u001b[A\n",
            " 19%|█▉        | 47/250 [03:00<12:27,  3.68s/it]\u001b[A\n",
            " 19%|█▉        | 48/250 [03:05<13:15,  3.94s/it]\u001b[A\n",
            " 20%|█▉        | 49/250 [03:10<14:20,  4.28s/it]\u001b[A\n",
            " 20%|██        | 50/250 [03:13<13:23,  4.02s/it]\u001b[A\n",
            " 20%|██        | 51/250 [03:17<12:41,  3.83s/it]\u001b[A\n",
            " 21%|██        | 52/250 [03:20<12:16,  3.72s/it]\u001b[A\n",
            " 21%|██        | 53/250 [03:26<12:48,  3.90s/it]\n",
            "  0%|          | 0/2 [03:27<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-7a5b379567a6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mout_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstart_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-20d3b07f53be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, img)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mencoder_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mnslRT1TI4Rx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}