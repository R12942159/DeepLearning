{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4yOcwPSJd4VXYx09Fct7L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/NTU_DLCV/blob/Hw3/p2_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13h-PqWce93k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from argparse import ArgumentParser\n",
        "from PIL import Image\n",
        "import clip\n",
        "import torch\n",
        "import language_evaluation\n",
        "\n",
        "\"\"\"\n",
        "You can run this evaluation code by the following command:\n",
        "```\n",
        "python3 p2_evaluate.py --pred_file <output_json_file_path> --images_root <image_folder_path> --annotation_file <annotation_json_file_path>\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "def readJSON(file_path):\n",
        "    try:\n",
        "        with open(file_path) as f:\n",
        "            data = json.load(f)\n",
        "        return data\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "\n",
        "def getGTCaptions(annotations):\n",
        "    img_id_to_name = {}\n",
        "    for img_info in annotations[\"images\"]:\n",
        "        img_name = img_info[\"file_name\"].replace(\".jpg\", \"\")\n",
        "        img_id_to_name[img_info[\"id\"]] = img_name\n",
        "\n",
        "    img_name_to_gts = defaultdict(list)\n",
        "    for ann_info in annotations[\"annotations\"]:\n",
        "        img_id = ann_info[\"image_id\"]\n",
        "        img_name = img_id_to_name[img_id]\n",
        "        img_name_to_gts[img_name].append(ann_info[\"caption\"])\n",
        "    return img_name_to_gts\n",
        "\n",
        "\n",
        "class CIDERScore:\n",
        "    def __init__(self):\n",
        "        self.evaluator = language_evaluation.CocoEvaluator(coco_types=[\"CIDEr\"])\n",
        "\n",
        "    def __call__(self, predictions, gts):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            predictions: dict of str\n",
        "            gts:         dict of list of str\n",
        "        Return:\n",
        "            cider_score: float\n",
        "        \"\"\"\n",
        "        # Collect predicts and answers\n",
        "        predicts = []\n",
        "        answers = []\n",
        "        for img_name in predictions.keys():\n",
        "            predicts.append(predictions[img_name])\n",
        "            answers.append(gts[img_name])\n",
        "\n",
        "        # Compute CIDEr score\n",
        "        results = self.evaluator.run_evaluation(predicts, answers)\n",
        "        return results['CIDEr']\n",
        "\n",
        "\n",
        "class CLIPScore:\n",
        "    def __init__(self):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model, self.preprocess = clip.load(\"ViT-B/32\", device=self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "    def __call__(self, predictions, images_root):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            predictions: dict of str\n",
        "            images_root: str\n",
        "        Return:\n",
        "            clip_score: float\n",
        "        \"\"\"\n",
        "        total_score = 0.\n",
        "\n",
        "        for img_name, pred_caption in predictions.items():\n",
        "            image_path = os.path.join(images_root, f\"{img_name}.jpg\")\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "            total_score += self.getCLIPScore(image, pred_caption)\n",
        "        return total_score / len(predictions)\n",
        "\n",
        "    def getCLIPScore(self, image, caption):\n",
        "        \"\"\"\n",
        "        This function computes CLIPScore based on the pseudocode in the slides.\n",
        "        Input:\n",
        "            image: PIL.Image\n",
        "            caption: str\n",
        "        Return:\n",
        "            cilp_score: float\n",
        "        \"\"\"\n",
        "        image_input = self.preprocess(image).unsqueeze(0).to(self.device)\n",
        "        text_input = clip.tokenize([caption]).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            image_features = self.model.encode_image(image_input)\n",
        "            text_features = self.model.encode_text(text_input)\n",
        "\n",
        "        cos_sim = torch.nn.functional.cosine_similarity(image_features, text_features).item()\n",
        "        return 2.5 * max(cos_sim, 0)\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    # Read data\n",
        "    predictions = readJSON(args.pred_file)\n",
        "    annotations = readJSON(args.annotation_file)\n",
        "\n",
        "    # Preprocess annotation file\n",
        "    gts = getGTCaptions(annotations)\n",
        "\n",
        "    # Check predictions content is correct\n",
        "    assert type(predictions) is dict\n",
        "    assert set(predictions.keys()) == set(gts.keys())\n",
        "    assert all([type(pred) is str for pred in predictions.values()])\n",
        "\n",
        "    # CIDErScore\n",
        "    cider_score = CIDERScore()(predictions, gts)\n",
        "\n",
        "    # CLIPScore\n",
        "    clip_score = CLIPScore()(predictions, args.images_root)\n",
        "\n",
        "    print(f\"CIDEr: {cider_score} | CLIPScore: {clip_score}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--pred_file\", help=\"Prediction json file\")\n",
        "    parser.add_argument(\"--images_root\", default=\"p2_data/images/val/\", help=\"Image root\")\n",
        "    parser.add_argument(\"--annotation_file\", default=\"p2_data/val.json\", help=\"Annotation json file\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    main(args)"
      ]
    }
  ]
}