{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/NTU_DLCV/blob/Hw3/p2_Image_caption_large_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "Xb59e3Ej2GPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import timm\n",
        "import json\n",
        "import torch\n",
        "import collections\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as tr\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from torch import nn, Tensor\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "SBi1aSqPhMuD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eg4VzCElm83",
        "outputId": "a0488c7c-c5e2-4a38-d35b-f65d14bcdc19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UVlQEx1nX6xD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54375cc5-336b-41a6-8490-64cd82cb106c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download dataset and unzip zip file."
      ],
      "metadata": {
        "id": "Q22ZX1_VhKiK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DG6GOxEHD9l"
      },
      "outputs": [],
      "source": [
        "!gdown 1SUiRrG6zQVtyrVSVh9hOBq5_fX-oV2Lh -O hw3_data.zip # 11rP6KmR5Qwjhx0rfag0b5TZGBTRuPtQR\n",
        "!unzip /content/hw3_data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizer ('<|endoftext|>', 50256) -> 250dim"
      ],
      "metadata": {
        "id": "sIMyluP4OcRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BPETokenizer:\n",
        "\n",
        "    def __init__(self, encoder_file, vocab_file):\n",
        "        with open(encoder_file, 'r', encoding='utf-8') as f:\n",
        "            self.encoder = json.load(f)\n",
        "        self.decoder = {v:k for k,v in self.encoder.items()}\n",
        "        with open(vocab_file, 'r', encoding='utf-8') as f:\n",
        "            vocab = f.read().split('\\n')[1:-1]\n",
        "        self.bpe_ranks = {tuple(line.split()): i for i, line in enumerate(vocab)}\n",
        "        assert len(self.encoder) == 50257 and len(self.bpe_ranks) == 49999 # len(self.bpe_ranks) == 50000\n",
        "        bs = list(range(33, 127)) + list(range(161, 256))\n",
        "        xs = list(range(0, 33)) + list(range(127, 161))\n",
        "        cs = bs[:] + [2**8 + i for i in range(len(xs))]\n",
        "        self.byte_encoder = dict(zip(bs + xs, [chr(n) for n in cs]))\n",
        "        self.byte_decoder = {v:k for k, v in self.byte_encoder.items()}\n",
        "\n",
        "    def encode(self, text, allowed_special=None):\n",
        "        tokens = re.findall(r\"\"\"<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d| ?\"\"\" +\n",
        "                            r\"\"\"\\w+| ?\\d+| ?[^\\s\\w\\d]+|\\s+(?!\\S)|\\s+\"\"\", text, re.UNICODE)\n",
        "        def translate(token):\n",
        "            if token == '<|endoftext|>':\n",
        "                assert allowed_special and token in allowed_special\n",
        "                return [token]\n",
        "            word = tuple(''.join(self.byte_encoder[byte] for byte in token.encode('utf-8')))\n",
        "            while len(word) != 1:\n",
        "                pairs = set((word[i], word[i+1]) for i in range(len(word)-1))\n",
        "                bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
        "                if bigram not in self.bpe_ranks:\n",
        "                    break\n",
        "                a, b = bigram\n",
        "                new_word = []\n",
        "                i = 0\n",
        "                while i < len(word):\n",
        "                    j = word.index(a, i) if a in word[i:] else len(word)\n",
        "                    new_word.extend(word[i:j])\n",
        "                    i = j\n",
        "                    if i < len(word):\n",
        "                        j = 2 if i < len(word)-1 and word[i] == a and word[i+1] == b else 1\n",
        "                        new_word.append(a+b if j == 2 else word[i])\n",
        "                        i += j\n",
        "                word = tuple(new_word)\n",
        "            return word\n",
        "        return [self.encoder[_] for token in tokens for _ in translate(token)]\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        tokens = [self.decoder[token] for token in tokens]\n",
        "        buffer = bytearray([self.byte_decoder[c] for c in ''.join(tokens)])\n",
        "        return buffer.decode('utf-8', errors='replace')"
      ],
      "metadata": {
        "id": "gjc6poP1OdBM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = BPETokenizer('/content/encoder.json', '/content/vocab.bpe')\n",
        "# prompt = 'a kitchen with a sink and many cooking machines and a pot of food'\n",
        "\n",
        "# text_embedding_len = 250\n",
        "\n",
        "# context = encoding.encode(prompt)\n",
        "# context = [50256] + context + [50256]*(text_embedding_len - len(context) - 1)\n",
        "# # context\n",
        "# encoding.decode(context)"
      ],
      "metadata": {
        "id": "6aeCuLyJOmhP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define function"
      ],
      "metadata": {
        "id": "L0JYrzNqE0mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def json_load(json_path: str):\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    return data"
      ],
      "metadata": {
        "id": "z5xRsOP3h96o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caption_with_id(json_path: str) -> list:\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        json_data = json.load(file)\n",
        "    data = [{'caption': row['caption'], 'image_id': row['image_id']} for row in json_data['annotations']]\n",
        "    return data"
      ],
      "metadata": {
        "id": "vVR-onWwmbCI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id2file_name(json_path: str) -> dict:\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        json_data = json.load(file)\n",
        "    data = {row['id']: row['file_name'] for row in json_data['images']}\n",
        "    return data"
      ],
      "metadata": {
        "id": "rWW6y2Q1o_t-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_joson_path = '/content/encoder.json'\n",
        "vocab_bpe_path = '/content/vocab.bpe'\n",
        "def collate_fn(batch, tokenizer=BPETokenizer(encoder_joson_path, vocab_bpe_path)):\n",
        "    # Get the individual elements of the batch\n",
        "    images = [item['img'] for item in batch]\n",
        "    captions = [item['caption'] for item in batch]\n",
        "    filenames = [item['filename'] for item in batch]\n",
        "\n",
        "    # Tokenize captions\n",
        "    tokenized_captions = [tokenizer.encode(caption) for caption in captions]\n",
        "\n",
        "    # Pad the vector length into stop token to dimension 250\n",
        "    text_len = 250 # text_embedding_len\n",
        "    tokenized_captions_train = [\n",
        "        [50256] + caption + [50256] * (text_len - len(caption) - 1) for caption in tokenized_captions\n",
        "    ]\n",
        "    tokenized_captions_inf = [\n",
        "        caption + [50256] + [-100] * (text_len - len(caption) - 1) for caption in tokenized_captions\n",
        "    ]\n",
        "\n",
        "    # Convert tokenized captions to PyTorch tensors\n",
        "    tokenized_captions_train = [torch.tensor(caption) for caption in tokenized_captions_train]\n",
        "    tokenized_captions_inf = [torch.tensor(caption) for caption in tokenized_captions_inf]\n",
        "\n",
        "    # Create a new batch with tokenized captions\n",
        "    tokenized_batch = {\n",
        "        'img': torch.stack(images, dim=0),\n",
        "        'tokenized_captions_train': torch.stack(tokenized_captions_train, dim=0),\n",
        "        'filename': filenames,\n",
        "        'tokenized_captions_inf': torch.stack(tokenized_captions_inf, dim=0),\n",
        "    }\n",
        "\n",
        "    return tokenized_batch"
      ],
      "metadata": {
        "id": "ZhTVXCheOYm6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Dataset"
      ],
      "metadata": {
        "id": "7TWHXZgugWOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImgCaptionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_dir, json_path, transform) -> None:\n",
        "        super(ImgCaptionDataset, self).__init__()\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Connect caption -> image_id -> file_name\n",
        "        self.caption_with_id = caption_with_id(json_path)\n",
        "        self.id2file_name = id2file_name(json_path)\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.caption_with_id)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        caption_id = self.caption_with_id[idx]\n",
        "        file_name = self.id2file_name[caption_id['image_id']]\n",
        "        img = Image.open(os.path.join(self.img_dir, file_name)).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        return {'img': img, 'caption': caption_id['caption'], 'filename': os.path.splitext(file_name)[0]}"
      ],
      "metadata": {
        "id": "qJq6lmbBlbaM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Dataloader"
      ],
      "metadata": {
        "id": "vMk7sUiwHEPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ImgCaptionDataset(\n",
        "    img_dir='/content/hw3_data/p2_data/images/train',\n",
        "    json_path='/content/hw3_data/p2_data/train.json',\n",
        "    transform=tr.Compose([\n",
        "        tr.Resize(224),\n",
        "        tr.CenterCrop(224),\n",
        "        tr.ToTensor(),\n",
        "        tr.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        ")\n",
        "val_ds = ImgCaptionDataset(\n",
        "    img_dir='/content/hw3_data/p2_data/images/val',\n",
        "    json_path='/content/hw3_data/p2_data/val.json',\n",
        "    transform=tr.Compose([\n",
        "        tr.Resize(224),\n",
        "        tr.CenterCrop(224),\n",
        "        tr.ToTensor(),\n",
        "        tr.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=16,\n",
        "    collate_fn=collate_fn,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=1,\n",
        "    collate_fn=collate_fn,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        ")"
      ],
      "metadata": {
        "id": "MMGD07vrHGiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8d8766-0a85-434e-e05e-6e98acabed12"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Config"
      ],
      "metadata": {
        "id": "Fx9an6CwEx-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "\n",
        "    def __init__(self, checkpoint=None):\n",
        "        self.n_layer = 12\n",
        "        self.n_head = 12\n",
        "        self.n_embd = 768\n",
        "        self.vocab_size = 50257\n",
        "        self.block_size = 1024\n",
        "        self.checkpoint = checkpoint"
      ],
      "metadata": {
        "id": "x39qAcvyEzgi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = Config(checkpoint='/content/hw3_data/p2_data/decoder_model.bin')"
      ],
      "metadata": {
        "id": "lLwivdnDE5eq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### timm's ViT encoder"
      ],
      "metadata": {
        "id": "HK4W-qWpE1eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder = timm.create_model('vit_large_patch16_224_in21k', pretrained=True) # vit_base_patch16_224_in21k"
      ],
      "metadata": {
        "id": "mw9GuLaaE24G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for batch in train_loader:\n",
        "#     img = batch['img']\n",
        "#     break"
      ],
      "metadata": {
        "id": "tYBaNf1TE_s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
        "#         x = self.patch_embed(x)\n",
        "#         x = self._pos_embed(x)\n",
        "#         x = self.patch_drop(x)\n",
        "#         x = self.norm_pre(x)\n",
        "# #\n",
        "#         x = self.blocks(x)\n",
        "#         for i, block in enumerate(self.blocks()):\n",
        "\n",
        "#           print(i)\n",
        "#         x = self.norm(x)\n",
        "#         return x"
      ],
      "metadata": {
        "id": "hSFseT7xmJEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with torch.no_grad():\n",
        "#     encoder_out = encoder.patch_embed(img)\n",
        "#     encoder_out = encoder._pos_embed(encoder_out)\n",
        "#     encoder_out = encoder.patch_drop(encoder_out)\n",
        "#     encoder_out = encoder.norm_pre(encoder_out)\n",
        "#     for i, block in enumerate(encoder.blocks):\n",
        "#         if i < 23:\n",
        "#             encoder_out = block(encoder_out)\n",
        "#             print(i)\n",
        "#     encoder_out = encoder.norm(encoder_out)"
      ],
      "metadata": {
        "id": "WP6PDoTWFBWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder_out.size()"
      ],
      "metadata": {
        "id": "AKn08vpIJB-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### decoder"
      ],
      "metadata": {
        "id": "w1QQ3sdc8GRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.c_attn = nn.Linear(cfg.n_embd, 3 * cfg.n_embd)\n",
        "        self.c_proj = nn.Linear(cfg.n_embd, cfg.n_embd)\n",
        "        self.n_head = cfg.n_head\n",
        "        self.n_embd = cfg.n_embd\n",
        "        size = cfg.block_size\n",
        "        self.register_buffer('bias', torch.tril(torch.ones(size, size)).view(1, 1, size, size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch, context, embedding\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        return self.c_proj((att @ v).transpose(1, 2).contiguous().view(B, T, C))\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.multihead_attn = nn.MultiheadAttention(cfg.n_embd, cfg.n_head, batch_first=True)\n",
        "\n",
        "    def forward(self, query, encoder_out):\n",
        "        \"\"\"\n",
        "        Q is the source from the decoder, K, V are the sources from the encoder.\n",
        "        Q: (N, L, Eq), where L is the target embedding dim, Eq is embed_dim and batch_first=True.\n",
        "        {K, V}: (N, L, E{k,v}), where L is the source embedding dim, E{k,v} is {k,v}_dim and batch_first=True.\n",
        "        \"\"\"\n",
        "        attn_output, attn_output_weights = self.multihead_attn(query, encoder_out, encoder_out)\n",
        "        return attn_output\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(cfg.n_embd)\n",
        "        self.ln_2 = nn.LayerNorm(cfg.n_embd)\n",
        "        self.ln_3 = nn.LayerNorm(cfg.n_embd) # add\n",
        "        self.attn = Attention(cfg)\n",
        "        self.crs_attn = CrossAttention(cfg) # add\n",
        "        self.mlp = nn.Sequential(collections.OrderedDict([\n",
        "            ('c_fc', nn.Linear(cfg.n_embd, 4 * cfg.n_embd)),\n",
        "            ('act', nn.GELU(approximate='tanh')),\n",
        "            ('c_proj', nn.Linear(4 * cfg.n_embd, cfg.n_embd))\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x, encoder_out) -> Tensor: # add\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.crs_attn(self.ln_3(x), self.ln_3(encoder_out)) # add\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.block_size = cfg.block_size\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(cfg.vocab_size, cfg.n_embd), # 文字投影\n",
        "            wpe = nn.Embedding(cfg.block_size, cfg.n_embd), # position\n",
        "            h = nn.Sequential(*[Block(cfg) for _ in range(cfg.n_layer)]), # Nx\n",
        "            ln_f = nn.LayerNorm(cfg.n_embd)\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(cfg.n_embd, cfg.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "        # timm's ViT encoder (vit_base_patch16_224_in21k,)\n",
        "        self.encoder = timm.create_model('vit_large_patch16_224_in21k', pretrained=True)\n",
        "        self.linear = nn.Linear(1024, cfg.n_embd) # [16, 197, 1024]\n",
        "        # load checkpoint\n",
        "        if self.cfg.checkpoint is not None:\n",
        "            state_dict = torch.load(self.cfg.checkpoint)\n",
        "            transposed = [ '.c_attn.weight', '.c_fc.weight', '.c_proj.weight' ]\n",
        "            for key, value in state_dict.items():\n",
        "                if any(key.endswith(w) for w in transposed):\n",
        "                    state_dict[key] = value.t()\n",
        "            self.transformer.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    def forward(self, x: Tensor, img: Tensor) -> Tensor: # add\n",
        "        x = torch.narrow(x, 1, 0, min(x.size(1), self.block_size))\n",
        "        pos = torch.arange(x.size()[1], dtype=torch.long, device=x.device).unsqueeze(0)\n",
        "        x = self.transformer.wte(x) + self.transformer.wpe(pos)\n",
        "        # encoder veatures\n",
        "        # encoder_out = self.encoder.forward_features(img)\n",
        "        encoder_out = self.encoder.patch_embed(img)\n",
        "        encoder_out = self.encoder._pos_embed(encoder_out)\n",
        "        encoder_out = self.encoder.patch_drop(encoder_out)\n",
        "        encoder_out = self.encoder.norm_pre(encoder_out)\n",
        "        for i, block in enumerate(self.encoder.blocks):\n",
        "            if i < 23:\n",
        "                encoder_out = block(encoder_out)\n",
        "        encoder_out = self.encoder.norm(encoder_out)\n",
        "\n",
        "        encoder_out = self.linear(encoder_out)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x, encoder_out)\n",
        "        x = self.lm_head(self.transformer.ln_f(x)) # add\n",
        "        return x"
      ],
      "metadata": {
        "id": "TYyI157L8JB7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ViT's forward_features"
      ],
      "metadata": {
        "id": "5YxoYwV1p-r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
        "#         x = self.patch_embed(x)\n",
        "#         x = self._pos_embed(x)\n",
        "#         x = self.patch_drop(x)\n",
        "#         x = self.norm_pre(x)\n",
        "\n",
        "#         x = self.blocks(x)\n",
        "#         for i, block in enumerate(self.blocks()):\n",
        "#           x = block(x)\n",
        "#         x = self.norm(x)\n",
        "#         return x"
      ],
      "metadata": {
        "id": "z8JRoDm0c0BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoding test"
      ],
      "metadata": {
        "id": "Nymq6RjQw0Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder = Decoder(cfg)"
      ],
      "metadata": {
        "id": "W7ItaTQyFM3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for batch in train_loader:\n",
        "#     img = batch['img']\n",
        "#     tokenized_captions_train = batch['tokenized_captions_train']\n",
        "#     tokenized_captions_inf = batch['tokenized_captions_inf']\n",
        "#     break"
      ],
      "metadata": {
        "id": "8iZRZyyLVqTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = decoder(tokenized_captions_train, img)"
      ],
      "metadata": {
        "id": "C9WhUVX3XUNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred.size(), tokenized_captions_train.size(), img.size(), tokenized_captions_inf.size()"
      ],
      "metadata": {
        "id": "-VDTQFh1jIkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding.decode(pred[0].argmax(dim=1).tolist())"
      ],
      "metadata": {
        "id": "9rVBzjCBAMC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_fn = nn.CrossEntropyLoss() # ignore_index=50256\n",
        "\n",
        "# pred = pred.reshape(-1, 50257)\n",
        "# tokenized_captions_inf = tokenized_captions_inf.reshape(-1)\n",
        "# loss_fn(pred, tokenized_captions_inf)"
      ],
      "metadata": {
        "id": "mZVS0SXWk7Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "rFEjEGPIj285"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training(dataloader, model, loss_fn, optimizer):\n",
        "\n",
        "    size = len(dataloader.dataset) # number of samples\n",
        "    num_batches = len(dataloader) # batches per epoch\n",
        "    epoch_loss = 0\n",
        "\n",
        "    model.train() # to training mode\n",
        "    for batch_i, data in enumerate(tqdm(dataloader)):\n",
        "        data['img'] = data['img'].to(device, non_blocking=True)\n",
        "        data['tokenized_captions_train'] = data['tokenized_captions_train'].to(device, non_blocking=True)\n",
        "        data['tokenized_captions_inf'] = data['tokenized_captions_inf'].to(device, non_blocking=True)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute prediction loss\n",
        "        pred = model(data['tokenized_captions_train'], data['img'])\n",
        "        # reshape to (B, C)\n",
        "        data['tokenized_captions_inf'] = data['tokenized_captions_inf'].reshape(-1)\n",
        "        pred = pred.reshape(-1, 50257)\n",
        "        loss = loss_fn(pred, data['tokenized_captions_inf']) # tokenized captions inf\n",
        "\n",
        "        # Optimization by gradients\n",
        "        loss.backward() # backpropagation to compute gradients\n",
        "        optimizer.step() # update model params\n",
        "\n",
        "        # write to logs\n",
        "        epoch_loss += loss.item() # tensor -> python value\n",
        "    return epoch_loss/num_batches"
      ],
      "metadata": {
        "id": "xH8HOqOGqM47"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(dataloader, model):\n",
        "    evaluation_dict = {}\n",
        "    for data in tqdm(dataloader):\n",
        "        img = data['img'].to(device)\n",
        "        file_name = data['filename']\n",
        "        start_token = torch.tensor([[50256]]).to(device)\n",
        "\n",
        "        for j in range(250):\n",
        "            with torch.no_grad():\n",
        "                pred = model(start_token, img)\n",
        "\n",
        "            out_token = pred.argmax(dim=2)[0][-1]\n",
        "            start_token = torch.cat((start_token, out_token.unsqueeze(0).unsqueeze(0)), dim=1)\n",
        "            end_token = torch.sum(start_token[0] == 50256).item()\n",
        "            if end_token == 2:\n",
        "                pred_token = start_token[start_token != 50256]\n",
        "                pred_token = pred_token.tolist()\n",
        "                pred_caption = encoding.decode(pred_token)\n",
        "                break\n",
        "\n",
        "        evaluation_dict[file_name[0]] = pred_caption\n",
        "        print('\\n', 'file name: ', file_name[0], '\\caption: ', evaluation_dict[file_name[0]])\n",
        "\n",
        "    json_string = json.dumps(evaluation_dict, indent=2)  # The indent parameter is optional and adds indentation for better readability\n",
        "    with open(f'/content/drive/MyDrive/NTU_DLCV/Hw3/p2_output_large/largeV1_epoch{i}_output.json', 'w') as json_file:\n",
        "        json_file.write(json_string)\n",
        "    print(f'---------- large params Saved ----------')"
      ],
      "metadata": {
        "id": "S7Ow0EqdthUj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Freeze parameters"
      ],
      "metadata": {
        "id": "rK5s8nX8uSAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Decoder(cfg).to(device)\n",
        "\n",
        "# Freeze parameters\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad=False\n",
        "    # print(f\"{name}: {param.requires_grad}\")\n",
        "# Unfreeze some parameters\n",
        "for name, params in model.named_parameters():\n",
        "    params.requires_grad = True if 'crs_attn' in name else params.requires_grad\n",
        "    params.requires_grad = True if 'ln_3' in name else params.requires_grad\n",
        "\n",
        "for params in model.linear.parameters():\n",
        "    params.requires_grad = True\n",
        "\n",
        "trainable_weights = [name for name, param in model.named_parameters() if param.requires_grad == True]\n",
        "print('Total params: ', sum(params.numel() for params in model.parameters() if params.requires_grad))\n",
        "\n",
        "# list for True\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.requires_grad}\")"
      ],
      "metadata": {
        "id": "vUlm2roufCIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check the model params less than 35M"
      ],
      "metadata": {
        "id": "cvlf9z12KZPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load('/content/trainable_weights', map_location=device), strict=False)\n",
        "print('Total params: ', sum(params.numel() for params in model.parameters() if params.requires_grad))"
      ],
      "metadata": {
        "id": "KSaZygA5Kh8H",
        "outputId": "cde0b250-5197-49f3-d4ec-2034d59dc614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total params:  29154048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training"
      ],
      "metadata": {
        "id": "s332-TZhKjq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 7\n",
        "lr=3e-4\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# logs\n",
        "logs = {\n",
        "    'train_loss': []\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train_loss = training(train_loader, model, loss_fn, optimizer)\n",
        "\n",
        "\n",
        "    print(f'EPOCH: {epoch:04d} \\train_loss: {train_loss:.4f}')\n",
        "\n",
        "    logs['train_loss'].append(train_loss)\n",
        "\n",
        "    # Save model\n",
        "    save_weights = {k: v for k, v in model.state_dict().items() if k in trainable_weights}\n",
        "    torch.save(save_weights, f'/content/drive/MyDrive/NTU_DLCV/Hw3/p2_ckpt_large/largeV1_lr{lr}_epoch{epoch}_{train_loss:.4f}.pth')\n",
        "    print(f'---------- epoch{epoch}: Model Save ----------')\n",
        "    inference(val_loader, model)"
      ],
      "metadata": {
        "id": "DEguocg8j4qa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "509ac052-222c-48d0-84ac-c7b55be813c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/7 [00:00<?, ?it/s]\n",
            "  0%|          | 0/3316 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/3316 [00:01<1:00:00,  1.09s/it]\u001b[A\n",
            "  0%|          | 2/3316 [00:01<39:32,  1.40it/s]  \u001b[A\n",
            "  0%|          | 3/3316 [00:01<32:31,  1.70it/s]\u001b[A\n",
            "  0%|          | 4/3316 [00:02<29:28,  1.87it/s]\u001b[A\n",
            "  0%|          | 5/3316 [00:02<27:44,  1.99it/s]\u001b[A\n",
            "  0%|          | 6/3316 [00:03<26:28,  2.08it/s]\u001b[A\n",
            "  0%|          | 7/3316 [00:03<25:44,  2.14it/s]\u001b[A\n",
            "  0%|          | 8/3316 [00:04<25:18,  2.18it/s]\u001b[A\n",
            "  0%|          | 9/3316 [00:04<25:11,  2.19it/s]\u001b[A\n",
            "  0%|          | 10/3316 [00:05<24:48,  2.22it/s]\u001b[A\n",
            "  0%|          | 11/3316 [00:05<24:39,  2.23it/s]\u001b[A\n",
            "  0%|          | 12/3316 [00:05<24:30,  2.25it/s]\u001b[A\n",
            "  0%|          | 13/3316 [00:06<24:28,  2.25it/s]\u001b[A\n",
            "  0%|          | 14/3316 [00:06<24:37,  2.24it/s]\u001b[A\n",
            "  0%|          | 15/3316 [00:07<24:35,  2.24it/s]\u001b[A\n",
            "  0%|          | 16/3316 [00:07<24:27,  2.25it/s]\u001b[A\n",
            "  1%|          | 17/3316 [00:08<24:37,  2.23it/s]\u001b[A\n",
            "  1%|          | 18/3316 [00:08<24:35,  2.24it/s]\u001b[A\n",
            "  1%|          | 19/3316 [00:09<24:45,  2.22it/s]\u001b[A\n",
            "  1%|          | 20/3316 [00:09<24:50,  2.21it/s]\u001b[A\n",
            "  1%|          | 21/3316 [00:10<24:44,  2.22it/s]\u001b[A\n",
            "  1%|          | 22/3316 [00:10<24:53,  2.21it/s]\u001b[A\n",
            "  1%|          | 23/3316 [00:10<25:05,  2.19it/s]\u001b[A\n",
            "  1%|          | 24/3316 [00:11<25:06,  2.19it/s]\u001b[A\n",
            "  1%|          | 25/3316 [00:11<25:09,  2.18it/s]\u001b[A\n",
            "  1%|          | 26/3316 [00:12<25:03,  2.19it/s]\u001b[A\n",
            "  1%|          | 27/3316 [00:12<25:07,  2.18it/s]\u001b[A\n",
            "  1%|          | 28/3316 [00:13<24:56,  2.20it/s]\u001b[A\n",
            "  1%|          | 29/3316 [00:13<24:38,  2.22it/s]\u001b[A\n",
            "  1%|          | 30/3316 [00:14<24:33,  2.23it/s]\u001b[A\n",
            "  1%|          | 31/3316 [00:14<24:34,  2.23it/s]\u001b[A\n",
            "  1%|          | 32/3316 [00:15<24:35,  2.23it/s]\u001b[A\n",
            "  1%|          | 33/3316 [00:15<24:38,  2.22it/s]\u001b[A\n",
            "  1%|          | 34/3316 [00:15<24:53,  2.20it/s]\u001b[A\n",
            "  1%|          | 35/3316 [00:16<24:46,  2.21it/s]\u001b[A\n",
            "  1%|          | 36/3316 [00:16<24:51,  2.20it/s]\u001b[A\n",
            "  1%|          | 37/3316 [00:17<24:52,  2.20it/s]\u001b[A\n",
            "  1%|          | 38/3316 [00:17<24:35,  2.22it/s]\u001b[A\n",
            "  1%|          | 39/3316 [00:18<24:28,  2.23it/s]\u001b[A\n",
            "  1%|          | 40/3316 [00:18<24:39,  2.21it/s]\u001b[A\n",
            "  1%|          | 41/3316 [00:19<24:30,  2.23it/s]\u001b[A\n",
            "  1%|▏         | 42/3316 [00:19<24:25,  2.23it/s]\u001b[A\n",
            "  1%|▏         | 43/3316 [00:19<24:24,  2.23it/s]\u001b[A\n",
            "  1%|▏         | 44/3316 [00:20<24:22,  2.24it/s]\u001b[A\n",
            "  1%|▏         | 45/3316 [00:20<24:20,  2.24it/s]\u001b[A\n",
            "  1%|▏         | 46/3316 [00:21<24:21,  2.24it/s]\u001b[A\n",
            "  1%|▏         | 47/3316 [00:21<24:16,  2.24it/s]\u001b[A\n",
            "  1%|▏         | 48/3316 [00:22<24:11,  2.25it/s]\u001b[A\n",
            "  1%|▏         | 49/3316 [00:22<24:08,  2.25it/s]\u001b[A\n",
            "  2%|▏         | 50/3316 [00:23<24:09,  2.25it/s]\u001b[A\n",
            "  2%|▏         | 51/3316 [00:23<24:14,  2.25it/s]\u001b[A\n",
            "  2%|▏         | 52/3316 [00:23<24:13,  2.25it/s]\u001b[A\n",
            "  2%|▏         | 53/3316 [00:24<24:11,  2.25it/s]\u001b[A\n",
            "  2%|▏         | 54/3316 [00:24<24:11,  2.25it/s]\u001b[A\n",
            "  2%|▏         | 55/3316 [00:25<24:04,  2.26it/s]\u001b[A\n",
            "  2%|▏         | 56/3316 [00:25<24:03,  2.26it/s]\u001b[A\n",
            "  2%|▏         | 57/3316 [00:26<24:03,  2.26it/s]\u001b[A\n",
            "  2%|▏         | 58/3316 [00:26<23:56,  2.27it/s]\u001b[A\n",
            "  2%|▏         | 59/3316 [00:27<24:01,  2.26it/s]\u001b[A\n",
            "  2%|▏         | 60/3316 [00:27<24:21,  2.23it/s]\u001b[A\n",
            "  2%|▏         | 61/3316 [00:27<24:21,  2.23it/s]\u001b[A\n",
            "  2%|▏         | 62/3316 [00:28<24:14,  2.24it/s]\u001b[A\n",
            "  2%|▏         | 63/3316 [00:28<24:17,  2.23it/s]\u001b[A\n",
            "  2%|▏         | 64/3316 [00:29<24:15,  2.23it/s]\u001b[A\n",
            "  2%|▏         | 65/3316 [00:29<24:23,  2.22it/s]\u001b[A\n",
            "  2%|▏         | 66/3316 [00:30<24:33,  2.21it/s]\u001b[A\n",
            "  2%|▏         | 67/3316 [00:30<24:34,  2.20it/s]\u001b[A\n",
            "  2%|▏         | 68/3316 [00:31<24:28,  2.21it/s]\u001b[A\n",
            "  2%|▏         | 69/3316 [00:31<24:41,  2.19it/s]\u001b[A\n",
            "  2%|▏         | 70/3316 [00:32<24:49,  2.18it/s]\u001b[A\n",
            "  2%|▏         | 71/3316 [00:32<24:35,  2.20it/s]\u001b[A\n",
            "  2%|▏         | 72/3316 [00:32<24:32,  2.20it/s]\u001b[A\n",
            "  2%|▏         | 73/3316 [00:33<24:23,  2.22it/s]\u001b[A\n",
            "  2%|▏         | 74/3316 [00:33<24:38,  2.19it/s]\u001b[A\n",
            "  2%|▏         | 75/3316 [00:34<24:46,  2.18it/s]\u001b[A\n",
            "  2%|▏         | 76/3316 [00:34<24:42,  2.19it/s]\u001b[A\n",
            "  2%|▏         | 77/3316 [00:35<24:37,  2.19it/s]\u001b[A\n",
            "  2%|▏         | 78/3316 [00:35<24:32,  2.20it/s]\u001b[A\n",
            "  2%|▏         | 79/3316 [00:36<24:25,  2.21it/s]\u001b[A\n",
            "  2%|▏         | 80/3316 [00:36<24:24,  2.21it/s]\u001b[A\n",
            "  2%|▏         | 81/3316 [00:37<24:16,  2.22it/s]\u001b[A\n",
            "  2%|▏         | 82/3316 [00:37<24:13,  2.23it/s]\u001b[A\n",
            "  3%|▎         | 83/3316 [00:37<24:10,  2.23it/s]\u001b[A\n",
            "  3%|▎         | 84/3316 [00:38<24:08,  2.23it/s]\u001b[A\n",
            "  3%|▎         | 85/3316 [00:38<24:06,  2.23it/s]\u001b[A\n",
            "  3%|▎         | 86/3316 [00:39<23:58,  2.25it/s]\u001b[A\n",
            "  3%|▎         | 87/3316 [00:39<23:53,  2.25it/s]\u001b[A\n",
            "  3%|▎         | 88/3316 [00:40<23:57,  2.25it/s]\u001b[A\n",
            "  3%|▎         | 89/3316 [00:40<23:51,  2.26it/s]\u001b[A\n",
            "  3%|▎         | 90/3316 [00:41<23:51,  2.25it/s]\u001b[A\n",
            "  3%|▎         | 91/3316 [00:41<23:58,  2.24it/s]\u001b[A\n",
            "  3%|▎         | 92/3316 [00:41<23:57,  2.24it/s]\u001b[A\n",
            "  3%|▎         | 93/3316 [00:42<24:00,  2.24it/s]\u001b[A\n",
            "  3%|▎         | 94/3316 [00:42<24:01,  2.23it/s]\u001b[A\n",
            "  3%|▎         | 95/3316 [00:43<23:58,  2.24it/s]\u001b[A\n",
            "  3%|▎         | 96/3316 [00:43<23:52,  2.25it/s]\u001b[A\n",
            "  3%|▎         | 97/3316 [00:44<23:57,  2.24it/s]\u001b[A\n",
            "  3%|▎         | 98/3316 [00:44<23:51,  2.25it/s]\u001b[A\n",
            "  3%|▎         | 99/3316 [00:45<23:54,  2.24it/s]\u001b[A\n",
            "  3%|▎         | 100/3316 [00:45<23:55,  2.24it/s]\u001b[A\n",
            "  3%|▎         | 101/3316 [00:45<23:53,  2.24it/s]\u001b[A\n",
            "  3%|▎         | 102/3316 [00:46<23:52,  2.24it/s]\u001b[A\n",
            "  3%|▎         | 103/3316 [00:46<24:02,  2.23it/s]\u001b[A\n",
            "  3%|▎         | 104/3316 [00:47<24:01,  2.23it/s]\u001b[A\n",
            "  3%|▎         | 105/3316 [00:47<24:17,  2.20it/s]\u001b[A\n",
            "  3%|▎         | 106/3316 [00:48<24:10,  2.21it/s]\u001b[A\n",
            "  3%|▎         | 107/3316 [00:48<24:17,  2.20it/s]\u001b[A\n",
            "  3%|▎         | 108/3316 [00:49<24:26,  2.19it/s]\u001b[A\n",
            "  3%|▎         | 109/3316 [00:49<24:18,  2.20it/s]\u001b[A\n",
            "  3%|▎         | 110/3316 [00:50<24:27,  2.19it/s]\u001b[A\n",
            "  3%|▎         | 111/3316 [00:50<24:29,  2.18it/s]\u001b[A\n",
            "  3%|▎         | 112/3316 [00:50<24:21,  2.19it/s]\u001b[A\n",
            "  3%|▎         | 113/3316 [00:51<24:21,  2.19it/s]\u001b[A\n",
            "  3%|▎         | 114/3316 [00:51<24:14,  2.20it/s]\u001b[A\n",
            "  3%|▎         | 115/3316 [00:52<24:15,  2.20it/s]\u001b[A\n",
            "  3%|▎         | 116/3316 [00:52<24:26,  2.18it/s]\u001b[A\n",
            "  4%|▎         | 117/3316 [00:53<24:18,  2.19it/s]\u001b[A\n",
            "  4%|▎         | 118/3316 [00:53<24:22,  2.19it/s]\u001b[A\n",
            "  4%|▎         | 119/3316 [00:54<24:16,  2.19it/s]\u001b[A\n",
            "  4%|▎         | 120/3316 [00:54<24:08,  2.21it/s]\u001b[A\n",
            "  4%|▎         | 121/3316 [00:55<24:28,  2.18it/s]\u001b[A\n",
            "  4%|▎         | 122/3316 [00:55<24:23,  2.18it/s]\u001b[A\n",
            "  4%|▎         | 123/3316 [00:55<24:22,  2.18it/s]\u001b[A\n",
            "  4%|▎         | 124/3316 [00:56<24:13,  2.20it/s]\u001b[A\n",
            "  4%|▍         | 125/3316 [00:56<24:03,  2.21it/s]\u001b[A\n",
            "  4%|▍         | 126/3316 [00:57<23:50,  2.23it/s]\u001b[A\n",
            "  4%|▍         | 127/3316 [00:57<23:52,  2.23it/s]\u001b[A\n",
            "  4%|▍         | 128/3316 [00:58<23:47,  2.23it/s]\u001b[A\n",
            "  4%|▍         | 129/3316 [00:58<23:43,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 130/3316 [00:59<23:43,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 131/3316 [00:59<23:42,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 132/3316 [01:00<23:39,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 133/3316 [01:00<23:38,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 134/3316 [01:00<23:38,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 135/3316 [01:01<23:39,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 136/3316 [01:01<23:37,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 137/3316 [01:02<23:41,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 138/3316 [01:02<23:39,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 139/3316 [01:03<23:35,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 140/3316 [01:03<23:35,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 141/3316 [01:04<23:35,  2.24it/s]\u001b[A\n",
            "  4%|▍         | 142/3316 [01:04<23:33,  2.25it/s]\u001b[A\n",
            "  4%|▍         | 143/3316 [01:04<23:30,  2.25it/s]\u001b[A\n",
            "  4%|▍         | 144/3316 [01:05<23:42,  2.23it/s]\u001b[A\n",
            "  4%|▍         | 145/3316 [01:05<23:50,  2.22it/s]\u001b[A\n",
            "  4%|▍         | 146/3316 [01:06<23:46,  2.22it/s]\u001b[A\n",
            "  4%|▍         | 147/3316 [01:06<23:47,  2.22it/s]\u001b[A\n",
            "  4%|▍         | 148/3316 [01:07<23:55,  2.21it/s]\u001b[A\n",
            "  4%|▍         | 149/3316 [01:07<23:47,  2.22it/s]\u001b[A\n",
            "  5%|▍         | 150/3316 [01:08<23:58,  2.20it/s]\u001b[A\n",
            "  5%|▍         | 151/3316 [01:08<24:02,  2.19it/s]\u001b[A\n",
            "  5%|▍         | 152/3316 [01:08<23:54,  2.21it/s]\u001b[A\n",
            "  5%|▍         | 153/3316 [01:09<23:54,  2.20it/s]\u001b[A\n",
            "  5%|▍         | 154/3316 [01:09<24:00,  2.19it/s]\u001b[A\n",
            "  5%|▍         | 155/3316 [01:10<24:12,  2.18it/s]\u001b[A\n",
            "  5%|▍         | 156/3316 [01:10<23:59,  2.19it/s]\u001b[A\n",
            "  5%|▍         | 157/3316 [01:11<23:43,  2.22it/s]\u001b[A\n",
            "  5%|▍         | 158/3316 [01:11<24:13,  2.17it/s]\u001b[A\n",
            "  5%|▍         | 159/3316 [01:12<24:12,  2.17it/s]\u001b[A\n",
            "  5%|▍         | 160/3316 [01:12<24:01,  2.19it/s]\u001b[A\n",
            "  5%|▍         | 161/3316 [01:13<23:54,  2.20it/s]\u001b[A\n",
            "  5%|▍         | 162/3316 [01:13<24:02,  2.19it/s]\u001b[A\n",
            "  5%|▍         | 163/3316 [01:14<23:53,  2.20it/s]\u001b[A\n",
            "  5%|▍         | 164/3316 [01:14<23:43,  2.21it/s]\u001b[A\n",
            "  5%|▍         | 165/3316 [01:14<23:43,  2.21it/s]\u001b[A\n",
            "  5%|▌         | 166/3316 [01:15<23:31,  2.23it/s]\u001b[A\n",
            "  5%|▌         | 167/3316 [01:15<23:27,  2.24it/s]\u001b[A\n",
            "  5%|▌         | 168/3316 [01:16<23:27,  2.24it/s]\u001b[A\n",
            "  5%|▌         | 169/3316 [01:16<23:34,  2.23it/s]\u001b[A\n",
            "  5%|▌         | 170/3316 [01:17<23:31,  2.23it/s]\u001b[A\n",
            "  5%|▌         | 171/3316 [01:17<23:29,  2.23it/s]\u001b[A\n",
            "  5%|▌         | 172/3316 [01:18<23:25,  2.24it/s]\u001b[A\n",
            "  5%|▌         | 173/3316 [01:18<23:27,  2.23it/s]\u001b[A\n",
            "  5%|▌         | 174/3316 [01:18<23:27,  2.23it/s]\u001b[A\n",
            "  5%|▌         | 175/3316 [01:19<23:20,  2.24it/s]\u001b[A\n",
            "  5%|▌         | 176/3316 [01:19<23:17,  2.25it/s]\u001b[A\n",
            "  5%|▌         | 177/3316 [01:20<23:18,  2.24it/s]\u001b[A\n",
            "  5%|▌         | 178/3316 [01:20<23:15,  2.25it/s]\u001b[A\n",
            "  5%|▌         | 179/3316 [01:21<23:14,  2.25it/s]\u001b[A\n",
            "  5%|▌         | 180/3316 [01:21<23:15,  2.25it/s]\u001b[A\n",
            "  5%|▌         | 181/3316 [01:22<23:18,  2.24it/s]\u001b[A\n",
            "  5%|▌         | 182/3316 [01:22<23:16,  2.24it/s]\u001b[A\n",
            "  6%|▌         | 183/3316 [01:22<23:21,  2.24it/s]\u001b[A\n",
            "  6%|▌         | 184/3316 [01:23<23:21,  2.23it/s]\u001b[A\n",
            "  6%|▌         | 185/3316 [01:23<23:21,  2.23it/s]\u001b[A\n",
            "  6%|▌         | 186/3316 [01:24<23:17,  2.24it/s]\u001b[A\n",
            "  6%|▌         | 187/3316 [01:24<23:12,  2.25it/s]\u001b[A\n",
            "  6%|▌         | 188/3316 [01:25<23:14,  2.24it/s]\u001b[A\n",
            "  6%|▌         | 189/3316 [01:25<23:30,  2.22it/s]\u001b[A\n",
            "  6%|▌         | 190/3316 [01:26<23:36,  2.21it/s]\u001b[A\n",
            "  6%|▌         | 191/3316 [01:26<23:33,  2.21it/s]\u001b[A\n",
            "  6%|▌         | 192/3316 [01:27<23:44,  2.19it/s]\u001b[A\n",
            "  6%|▌         | 193/3316 [01:27<23:56,  2.17it/s]\u001b[A\n",
            "  6%|▌         | 194/3316 [01:27<23:53,  2.18it/s]\u001b[A\n",
            "  6%|▌         | 195/3316 [01:28<23:54,  2.18it/s]\u001b[A\n",
            "  6%|▌         | 196/3316 [01:28<23:38,  2.20it/s]\u001b[A\n",
            "  6%|▌         | 197/3316 [01:29<23:37,  2.20it/s]\u001b[A\n",
            "  6%|▌         | 198/3316 [01:29<23:39,  2.20it/s]\u001b[A\n",
            "  6%|▌         | 199/3316 [01:30<23:28,  2.21it/s]\u001b[A\n",
            "  6%|▌         | 200/3316 [01:30<23:17,  2.23it/s]\u001b[A\n",
            "  6%|▌         | 201/3316 [01:31<23:31,  2.21it/s]\u001b[A\n",
            "  6%|▌         | 202/3316 [01:31<23:41,  2.19it/s]\u001b[A\n",
            "  6%|▌         | 203/3316 [01:32<23:36,  2.20it/s]\u001b[A\n",
            "  6%|▌         | 204/3316 [01:32<23:26,  2.21it/s]\u001b[A\n",
            "  6%|▌         | 205/3316 [01:32<23:22,  2.22it/s]\u001b[A\n",
            "  6%|▌         | 206/3316 [01:33<23:17,  2.23it/s]\u001b[A\n",
            "  6%|▌         | 207/3316 [01:33<23:11,  2.23it/s]\u001b[A\n",
            "  6%|▋         | 208/3316 [01:34<23:09,  2.24it/s]\u001b[A\n",
            "  6%|▋         | 209/3316 [01:34<23:13,  2.23it/s]\u001b[A\n",
            "  6%|▋         | 210/3316 [01:35<23:11,  2.23it/s]\u001b[A\n",
            "  6%|▋         | 211/3316 [01:35<23:03,  2.24it/s]\u001b[A\n",
            "  6%|▋         | 212/3316 [01:36<23:07,  2.24it/s]\u001b[A\n",
            "  6%|▋         | 213/3316 [01:36<23:04,  2.24it/s]\u001b[A\n",
            "  6%|▋         | 214/3316 [01:36<23:07,  2.23it/s]\u001b[A\n",
            "  6%|▋         | 215/3316 [01:37<23:11,  2.23it/s]\u001b[A\n",
            "  7%|▋         | 216/3316 [01:37<23:10,  2.23it/s]\u001b[A\n",
            "  7%|▋         | 217/3316 [01:38<23:07,  2.23it/s]\u001b[A\n",
            "  7%|▋         | 218/3316 [01:38<23:02,  2.24it/s]\u001b[A\n",
            "  7%|▋         | 219/3316 [01:39<23:05,  2.24it/s]\u001b[A\n",
            "  7%|▋         | 220/3316 [01:39<23:04,  2.24it/s]\u001b[A\n",
            "  7%|▋         | 221/3316 [01:40<23:06,  2.23it/s]\u001b[A\n",
            "  7%|▋         | 222/3316 [01:40<23:01,  2.24it/s]\u001b[A\n",
            "  7%|▋         | 223/3316 [01:40<22:57,  2.24it/s]\u001b[A\n",
            "  7%|▋         | 224/3316 [01:41<22:56,  2.25it/s]\u001b[A\n",
            "  7%|▋         | 225/3316 [01:41<22:52,  2.25it/s]\u001b[A\n",
            "  7%|▋         | 226/3316 [01:42<22:54,  2.25it/s]\u001b[A\n",
            "  7%|▋         | 227/3316 [01:42<22:48,  2.26it/s]\u001b[A\n",
            "  7%|▋         | 228/3316 [01:43<22:50,  2.25it/s]\u001b[A\n",
            "  7%|▋         | 229/3316 [01:43<23:18,  2.21it/s]\u001b[A\n",
            "  7%|▋         | 230/3316 [01:44<23:15,  2.21it/s]\u001b[A\n",
            "  7%|▋         | 231/3316 [01:44<23:15,  2.21it/s]\u001b[A\n",
            "  7%|▋         | 232/3316 [01:44<23:13,  2.21it/s]\u001b[A\n",
            "  7%|▋         | 233/3316 [01:45<23:22,  2.20it/s]\u001b[A\n",
            "  7%|▋         | 234/3316 [01:45<23:21,  2.20it/s]\u001b[A\n",
            "  7%|▋         | 235/3316 [01:46<23:25,  2.19it/s]\u001b[A\n",
            "  7%|▋         | 236/3316 [01:46<23:35,  2.18it/s]\u001b[A\n",
            "  7%|▋         | 237/3316 [01:47<23:41,  2.17it/s]\u001b[A\n",
            "  7%|▋         | 238/3316 [01:47<23:39,  2.17it/s]\u001b[A\n",
            "  7%|▋         | 239/3316 [01:48<23:37,  2.17it/s]\u001b[A\n",
            "  7%|▋         | 240/3316 [01:48<23:47,  2.15it/s]\u001b[A\n",
            "  7%|▋         | 241/3316 [01:49<23:32,  2.18it/s]\u001b[A\n",
            "  7%|▋         | 242/3316 [01:49<23:40,  2.16it/s]\u001b[A\n",
            "  7%|▋         | 243/3316 [01:50<23:25,  2.19it/s]\u001b[A\n",
            "  7%|▋         | 244/3316 [01:50<23:36,  2.17it/s]\u001b[A\n",
            "  7%|▋         | 245/3316 [01:50<23:31,  2.18it/s]\u001b[A\n",
            "  7%|▋         | 246/3316 [01:51<23:20,  2.19it/s]\u001b[A\n",
            "  7%|▋         | 247/3316 [01:51<23:05,  2.21it/s]\u001b[A\n",
            "  7%|▋         | 248/3316 [01:52<22:57,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 249/3316 [01:52<22:56,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 250/3316 [01:53<22:54,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 251/3316 [01:53<22:51,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 252/3316 [01:54<22:53,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 253/3316 [01:54<22:48,  2.24it/s]\u001b[A\n",
            "  8%|▊         | 254/3316 [01:55<23:07,  2.21it/s]\u001b[A\n",
            "  8%|▊         | 255/3316 [01:55<23:03,  2.21it/s]\u001b[A\n",
            "  8%|▊         | 256/3316 [01:55<22:58,  2.22it/s]\u001b[A\n",
            "  8%|▊         | 257/3316 [01:56<22:53,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 258/3316 [01:56<22:51,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 259/3316 [01:57<22:52,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 260/3316 [01:57<22:44,  2.24it/s]\u001b[A\n",
            "  8%|▊         | 261/3316 [01:58<22:44,  2.24it/s]\u001b[A\n",
            "  8%|▊         | 262/3316 [01:58<22:44,  2.24it/s]\u001b[A\n",
            "  8%|▊         | 263/3316 [01:59<22:44,  2.24it/s]\u001b[A\n",
            "  8%|▊         | 264/3316 [01:59<22:45,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 265/3316 [01:59<22:49,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 266/3316 [02:00<22:47,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 267/3316 [02:00<22:40,  2.24it/s]\u001b[A\n",
            "  8%|▊         | 268/3316 [02:01<22:41,  2.24it/s]\u001b[A\n",
            "  8%|▊         | 269/3316 [02:01<22:45,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 270/3316 [02:02<22:48,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 271/3316 [02:02<22:46,  2.23it/s]\u001b[A\n",
            "  8%|▊         | 272/3316 [02:03<23:06,  2.20it/s]\u001b[A\n",
            "  8%|▊         | 273/3316 [02:03<23:08,  2.19it/s]\u001b[A\n",
            "  8%|▊         | 274/3316 [02:04<23:02,  2.20it/s]\u001b[A\n",
            "  8%|▊         | 275/3316 [02:04<22:55,  2.21it/s]\u001b[A\n",
            "  8%|▊         | 276/3316 [02:04<22:57,  2.21it/s]\u001b[A\n",
            "  8%|▊         | 277/3316 [02:05<22:55,  2.21it/s]\u001b[A\n",
            "  8%|▊         | 278/3316 [02:05<23:08,  2.19it/s]\u001b[A\n",
            "  8%|▊         | 279/3316 [02:06<23:00,  2.20it/s]\u001b[A\n",
            "  8%|▊         | 280/3316 [02:06<22:53,  2.21it/s]\u001b[A\n",
            "  8%|▊         | 281/3316 [02:07<22:48,  2.22it/s]\u001b[A\n",
            "  9%|▊         | 282/3316 [02:07<22:37,  2.23it/s]\u001b[A\n",
            "  9%|▊         | 283/3316 [02:08<22:51,  2.21it/s]\u001b[A\n",
            "  9%|▊         | 284/3316 [02:08<22:57,  2.20it/s]\u001b[A\n",
            "  9%|▊         | 285/3316 [02:08<23:05,  2.19it/s]\u001b[A\n",
            "  9%|▊         | 286/3316 [02:09<22:53,  2.21it/s]\u001b[A\n",
            "  9%|▊         | 287/3316 [02:09<23:09,  2.18it/s]\u001b[A\n",
            "  9%|▊         | 288/3316 [02:10<22:59,  2.20it/s]\u001b[A\n",
            "  9%|▊         | 289/3316 [02:10<22:50,  2.21it/s]\u001b[A\n",
            "  9%|▊         | 290/3316 [02:11<22:40,  2.22it/s]\u001b[A\n",
            "  9%|▉         | 291/3316 [02:11<22:40,  2.22it/s]\u001b[A\n",
            "  9%|▉         | 292/3316 [02:12<22:37,  2.23it/s]\u001b[A\n",
            "  9%|▉         | 293/3316 [02:12<22:37,  2.23it/s]\u001b[A\n",
            "  9%|▉         | 294/3316 [02:13<22:34,  2.23it/s]\u001b[A\n",
            "  9%|▉         | 295/3316 [02:13<22:30,  2.24it/s]\u001b[A\n",
            "  9%|▉         | 296/3316 [02:13<22:27,  2.24it/s]\u001b[A\n",
            "  9%|▉         | 297/3316 [02:14<22:31,  2.23it/s]\u001b[A\n",
            "  9%|▉         | 298/3316 [02:14<22:29,  2.24it/s]\u001b[A\n",
            "  9%|▉         | 299/3316 [02:15<22:26,  2.24it/s]\u001b[A\n",
            "  9%|▉         | 300/3316 [02:15<22:23,  2.25it/s]\u001b[A\n",
            "  9%|▉         | 301/3316 [02:16<22:25,  2.24it/s]\u001b[A\n",
            "  9%|▉         | 302/3316 [02:16<22:22,  2.25it/s]\u001b[A\n",
            "  9%|▉         | 303/3316 [02:17<22:28,  2.23it/s]\u001b[A\n",
            "  9%|▉         | 304/3316 [02:17<22:31,  2.23it/s]\u001b[A\n",
            "  9%|▉         | 305/3316 [02:17<22:28,  2.23it/s]\u001b[A\n",
            "  9%|▉         | 306/3316 [02:18<22:29,  2.23it/s]\u001b[A\n",
            "  9%|▉         | 307/3316 [02:18<22:24,  2.24it/s]\u001b[A\n",
            "  9%|▉         | 308/3316 [02:19<22:22,  2.24it/s]\u001b[A\n",
            "  9%|▉         | 309/3316 [02:19<22:25,  2.23it/s]\u001b[A\n",
            "  9%|▉         | 310/3316 [02:20<22:20,  2.24it/s]\u001b[A\n",
            "  9%|▉         | 311/3316 [02:20<22:20,  2.24it/s]\u001b[A\n",
            "  9%|▉         | 312/3316 [02:21<22:28,  2.23it/s]\u001b[A\n",
            "  9%|▉         | 313/3316 [02:21<22:47,  2.20it/s]\u001b[A\n",
            "  9%|▉         | 314/3316 [02:22<22:50,  2.19it/s]\u001b[A\n",
            "  9%|▉         | 315/3316 [02:22<22:42,  2.20it/s]\u001b[A\n",
            " 10%|▉         | 316/3316 [02:22<22:46,  2.20it/s]\u001b[A\n",
            " 10%|▉         | 317/3316 [02:23<22:35,  2.21it/s]\u001b[A\n",
            " 10%|▉         | 318/3316 [02:23<22:36,  2.21it/s]\u001b[A\n",
            " 10%|▉         | 319/3316 [02:24<22:35,  2.21it/s]\u001b[A\n",
            " 10%|▉         | 320/3316 [02:24<22:46,  2.19it/s]\u001b[A\n",
            " 10%|▉         | 321/3316 [02:25<22:39,  2.20it/s]\u001b[A\n",
            " 10%|▉         | 322/3316 [02:25<22:57,  2.17it/s]\u001b[A\n",
            " 10%|▉         | 323/3316 [02:26<22:43,  2.19it/s]\u001b[A\n",
            " 10%|▉         | 324/3316 [02:26<22:46,  2.19it/s]\u001b[A\n",
            " 10%|▉         | 325/3316 [02:27<22:51,  2.18it/s]\u001b[A\n",
            " 10%|▉         | 326/3316 [02:27<22:46,  2.19it/s]\u001b[A\n",
            " 10%|▉         | 327/3316 [02:27<22:53,  2.18it/s]\u001b[A\n",
            " 10%|▉         | 328/3316 [02:28<22:46,  2.19it/s]\u001b[A\n",
            " 10%|▉         | 329/3316 [02:28<22:40,  2.20it/s]\u001b[A\n",
            " 10%|▉         | 330/3316 [02:29<22:38,  2.20it/s]\u001b[A\n",
            " 10%|▉         | 331/3316 [02:29<22:54,  2.17it/s]\u001b[A\n",
            " 10%|█         | 332/3316 [02:30<22:40,  2.19it/s]\u001b[A\n",
            " 10%|█         | 333/3316 [02:30<22:33,  2.20it/s]\u001b[A\n",
            " 10%|█         | 334/3316 [02:31<22:23,  2.22it/s]\u001b[A\n",
            " 10%|█         | 335/3316 [02:31<22:12,  2.24it/s]\u001b[A\n",
            " 10%|█         | 336/3316 [02:31<22:09,  2.24it/s]\u001b[A\n",
            " 10%|█         | 337/3316 [02:32<22:08,  2.24it/s]\u001b[A\n",
            " 10%|█         | 338/3316 [02:32<22:00,  2.25it/s]\u001b[A\n",
            " 10%|█         | 339/3316 [02:33<22:16,  2.23it/s]\u001b[A\n",
            " 10%|█         | 340/3316 [02:33<22:12,  2.23it/s]\u001b[A\n",
            " 10%|█         | 341/3316 [02:34<22:12,  2.23it/s]\u001b[A\n",
            " 10%|█         | 342/3316 [02:34<22:09,  2.24it/s]\u001b[A\n",
            " 10%|█         | 343/3316 [02:35<22:10,  2.23it/s]\u001b[A\n",
            " 10%|█         | 344/3316 [02:35<22:04,  2.24it/s]\u001b[A\n",
            " 10%|█         | 345/3316 [02:36<22:03,  2.24it/s]\u001b[A\n",
            " 10%|█         | 346/3316 [02:36<22:06,  2.24it/s]\u001b[A\n",
            " 10%|█         | 347/3316 [02:36<22:11,  2.23it/s]\u001b[A\n",
            " 10%|█         | 348/3316 [02:37<22:09,  2.23it/s]\u001b[A\n",
            " 11%|█         | 349/3316 [02:37<22:13,  2.23it/s]\u001b[A\n",
            " 11%|█         | 350/3316 [02:38<22:13,  2.22it/s]\u001b[A\n",
            " 11%|█         | 351/3316 [02:38<22:13,  2.22it/s]\u001b[A\n",
            " 11%|█         | 352/3316 [02:39<22:14,  2.22it/s]\u001b[A\n",
            " 11%|█         | 353/3316 [02:39<22:12,  2.22it/s]\u001b[A\n",
            " 11%|█         | 354/3316 [02:40<22:05,  2.23it/s]\u001b[A\n",
            " 11%|█         | 355/3316 [02:40<22:11,  2.22it/s]\u001b[A\n",
            " 11%|█         | 356/3316 [02:40<22:22,  2.21it/s]\u001b[A\n",
            " 11%|█         | 357/3316 [02:41<22:34,  2.18it/s]\u001b[A\n",
            " 11%|█         | 358/3316 [02:41<22:36,  2.18it/s]\u001b[A\n",
            " 11%|█         | 359/3316 [02:42<22:30,  2.19it/s]\u001b[A\n",
            " 11%|█         | 360/3316 [02:42<22:47,  2.16it/s]\u001b[A\n",
            " 11%|█         | 361/3316 [02:43<22:34,  2.18it/s]\u001b[A\n",
            " 11%|█         | 362/3316 [02:43<22:44,  2.17it/s]\u001b[A\n",
            " 11%|█         | 363/3316 [02:44<22:43,  2.17it/s]\u001b[A\n",
            " 11%|█         | 364/3316 [02:44<22:37,  2.17it/s]\u001b[A\n",
            " 11%|█         | 365/3316 [02:45<22:29,  2.19it/s]\u001b[A\n",
            " 11%|█         | 366/3316 [02:45<22:19,  2.20it/s]\u001b[A\n",
            " 11%|█         | 367/3316 [02:46<22:15,  2.21it/s]\u001b[A\n",
            " 11%|█         | 368/3316 [02:46<22:23,  2.19it/s]\u001b[A\n",
            " 11%|█         | 369/3316 [02:46<22:10,  2.22it/s]\u001b[A\n",
            " 11%|█         | 370/3316 [02:47<22:04,  2.22it/s]\u001b[A\n",
            " 11%|█         | 371/3316 [02:47<22:06,  2.22it/s]\u001b[A\n",
            " 11%|█         | 372/3316 [02:48<22:14,  2.21it/s]\u001b[A\n",
            " 11%|█         | 373/3316 [02:48<22:26,  2.19it/s]\u001b[A\n",
            " 11%|█▏        | 374/3316 [02:49<22:19,  2.20it/s]\u001b[A\n",
            " 11%|█▏        | 375/3316 [02:49<22:10,  2.21it/s]\u001b[A\n",
            " 11%|█▏        | 376/3316 [02:50<22:09,  2.21it/s]\u001b[A\n",
            " 11%|█▏        | 377/3316 [02:50<21:59,  2.23it/s]\u001b[A\n",
            " 11%|█▏        | 378/3316 [02:50<21:59,  2.23it/s]\u001b[A\n",
            " 11%|█▏        | 379/3316 [02:51<21:59,  2.23it/s]\u001b[A\n",
            " 11%|█▏        | 380/3316 [02:51<22:00,  2.22it/s]\u001b[A\n",
            " 11%|█▏        | 381/3316 [02:52<21:58,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 382/3316 [02:52<22:00,  2.22it/s]\u001b[A\n",
            " 12%|█▏        | 383/3316 [02:53<21:52,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 384/3316 [02:53<21:47,  2.24it/s]\u001b[A\n",
            " 12%|█▏        | 385/3316 [02:54<21:55,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 386/3316 [02:54<21:51,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 387/3316 [02:55<21:48,  2.24it/s]\u001b[A\n",
            " 12%|█▏        | 388/3316 [02:55<21:49,  2.24it/s]\u001b[A\n",
            " 12%|█▏        | 389/3316 [02:55<21:50,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 390/3316 [02:56<21:53,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 391/3316 [02:56<21:52,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 392/3316 [02:57<21:46,  2.24it/s]\u001b[A\n",
            " 12%|█▏        | 393/3316 [02:57<21:47,  2.24it/s]\u001b[A\n",
            " 12%|█▏        | 394/3316 [02:58<21:48,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 395/3316 [02:58<21:49,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 396/3316 [02:59<21:49,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 397/3316 [02:59<21:51,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 398/3316 [02:59<21:52,  2.22it/s]\u001b[A\n",
            " 12%|█▏        | 399/3316 [03:00<21:50,  2.23it/s]\u001b[A\n",
            " 12%|█▏        | 400/3316 [03:00<22:06,  2.20it/s]\u001b[A\n",
            " 12%|█▏        | 401/3316 [03:01<21:58,  2.21it/s]\u001b[A\n",
            " 12%|█▏        | 402/3316 [03:01<22:16,  2.18it/s]\u001b[A\n",
            " 12%|█▏        | 403/3316 [03:02<22:15,  2.18it/s]\u001b[A\n",
            " 12%|█▏        | 404/3316 [03:02<22:03,  2.20it/s]\u001b[A\n",
            " 12%|█▏        | 405/3316 [03:03<22:13,  2.18it/s]\u001b[A\n",
            " 12%|█▏        | 406/3316 [03:03<22:02,  2.20it/s]\u001b[A\n",
            " 12%|█▏        | 407/3316 [03:04<22:00,  2.20it/s]\u001b[A\n",
            " 12%|█▏        | 408/3316 [03:04<21:52,  2.21it/s]\u001b[A\n",
            " 12%|█▏        | 409/3316 [03:05<21:59,  2.20it/s]\n",
            "  0%|          | 0/7 [03:05<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-59321e2284d7>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-a97d2eedf837>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# write to logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tensor -> python value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### inference"
      ],
      "metadata": {
        "id": "K4qEtiUZcjqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown 1UxILFtGRu8uWnkFKliUwrbKre_u84WvF -O trainable_weights0\n",
        "# !gdown 1-4LS5WGhXkrkkThaEzGBCFVUZz8mZqa8 -O trainable_weights1\n",
        "# !gdown 1-D6DX6pkUuWH5mpTsq-dyLUv6rdeYk3T -O trainable_weights2\n",
        "!gdown 1-Lb8oPWHfijBx0HtxmMGLq4UNfw4sekr -O trainable_weights3\n",
        "!gdown 1-MLqlovIk4GGsORHiQbJdhg-cgqdoLbt -O trainable_weights4"
      ],
      "metadata": {
        "id": "DqSfWMRZcvbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3, 5):\n",
        "    model = Decoder(cfg).to(device)\n",
        "    model.load_state_dict(torch.load(f'/content/trainable_weights{i}', map_location=device), strict=False)\n",
        "    print(f'---------- trainable weights {i} is using ----------')\n",
        "\n",
        "    evaluation_dict = {}\n",
        "    for data in tqdm(val_loader):\n",
        "        img = data['img'].to(device)\n",
        "        file_name = data['filename']\n",
        "        start_token = torch.tensor([[50256]]).to(device)\n",
        "\n",
        "        for j in range(250):\n",
        "            with torch.no_grad():\n",
        "                pred = model(start_token, img)\n",
        "\n",
        "            out_token = pred.argmax(dim=2)[0][-1]\n",
        "            start_token = torch.cat((start_token, out_token.unsqueeze(0).unsqueeze(0)), dim=1)\n",
        "            end_token = torch.sum(start_token[0] == 50256).item()\n",
        "            if end_token == 2:\n",
        "                pred_token = start_token[start_token != 50256]\n",
        "                pred_token = pred_token.tolist()\n",
        "                pred_caption = encoding.decode(pred_token)\n",
        "                break\n",
        "\n",
        "        evaluation_dict[file_name[0]] = pred_caption\n",
        "        print('\\n', 'file name: ', file_name[0], '\\caption: ', evaluation_dict[file_name[0]])\n",
        "\n",
        "    json_string = json.dumps(evaluation_dict, indent=2)  # The indent parameter is optional and adds indentation for better readability\n",
        "    with open(f'/content/drive/MyDrive/NTU_DLCV/Hw3/p2_output_large/large_epoch{i}_output.json', 'w') as json_file:\n",
        "        json_file.write(json_string)\n",
        "    print(f'---------- Epoch{i} large params Saved ----------')"
      ],
      "metadata": {
        "id": "GnNNQ6q4GO9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rym4xyAFL1qS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}