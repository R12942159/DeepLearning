{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdgyJmtSIjbitWSgJNY63y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/DeepLearning/blob/main/DLCV_hw1_p3_plot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Rz-UUBh5k9JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "# Get cuda from GPU device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")"
      ],
      "metadata": {
        "id": "3h9NcwWdk-kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "class LandDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_paths, transform):\n",
        "        self.img_paths = img_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get img path\n",
        "        img_path = self.img_paths[idx]\n",
        "        # Read img\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        # Normalize Image with VGG16's mean and std\n",
        "        # (H, W, C) -> (C, H, W)\n",
        "        img = self.transform(img)\n",
        "\n",
        "        return img, os.path.basename(self.img_paths[idx])"
      ],
      "metadata": {
        "id": "zGu9O1Ggjsjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths = '/content/drive/MyDrive/NTU_DLCV/p3_data/train'\n",
        "img_paths_train = sorted([os.path.join(train_paths, i) for i in os.listdir(train_paths) if i.endswith('.jpg')])\n",
        "\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "test_ds = LandDataset(img_paths_train,\n",
        "                       transform = tr.Compose([\n",
        "                          tr.ToTensor(),\n",
        "                          tr.Normalize(mean=mean, std=std),\n",
        "                          ]),\n",
        "                      )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=4, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "ROqe7X5Llr2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.segmentation.deeplabv3 import deeplabv3_resnet101, DeepLabHead, FCNHead\n",
        "\n",
        "\n",
        "def deeplabv3(mode, num_classes=7):\n",
        "    if mode == 'resnet101':\n",
        "        model =  deeplabv3_resnet101(pretrained=True)\n",
        "        model.aux_classifier = FCNHead(1024, num_classes)\n",
        "        model.classifier = DeepLabHead(2048, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "def resnet_model(path):\n",
        "    model = deeplabv3(mode='resnet101')\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "f4Oes2rAlCxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_size(batch_preds, batch_names, out_path):\n",
        "    # batch_preds = (b, H, W)\n",
        "    for pred, name in zip(batch_preds, batch_names):\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        pred_img = np.zeros((512, 512, 3), dtype=np.uint8)\n",
        "        pred_img[np.where(pred == 0)] = [0, 255, 255]\n",
        "        pred_img[np.where(pred == 1)] = [255, 255, 0]\n",
        "        pred_img[np.where(pred == 2)] = [255, 0, 255]\n",
        "        pred_img[np.where(pred == 3)] = [0, 255, 0]\n",
        "        pred_img[np.where(pred == 4)] = [0, 0, 255]\n",
        "        pred_img[np.where(pred == 5)] = [255, 255, 255]\n",
        "        pred_img[np.where(pred == 6)] = [0, 0, 0]\n",
        "        imageio.imwrite(os.path.join(\n",
        "            out_path, name.replace('.jpg', '.png')), pred_img)"
      ],
      "metadata": {
        "id": "oP5BL2V5ml9f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}