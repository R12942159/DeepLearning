{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOEUO46OfM4iAW/wfmt53k4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/DeepLearning/blob/main/DLCV_hw1_p3_UNetplot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Rz-UUBh5k9JZ",
        "outputId": "8b357b2e-4177-400d-ba15-6cdc229f30d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "# Get cuda from GPU device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")"
      ],
      "metadata": {
        "id": "3h9NcwWdk-kh",
        "outputId": "f3617b25-f1bb-486b-e46e-abb2489379e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "train_paths = '/content/drive/MyDrive/NTU_DLCV/p3_data/train_plot'\n",
        "img_paths_train = sorted([os.path.join(train_paths, i) for i in os.listdir(train_paths) if i.endswith('.jpg')])"
      ],
      "metadata": {
        "id": "kBdnQDsQYP_U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "class LandDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_paths, transform):\n",
        "        self.img_paths = img_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "\n",
        "        return img, os.path.basename(self.img_paths[idx])"
      ],
      "metadata": {
        "id": "zGu9O1Ggjsjm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms as tr\n",
        "\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "test_ds = LandDataset(img_paths_train,\n",
        "                       transform = tr.Compose([\n",
        "                          tr.ToTensor(),\n",
        "                          tr.Normalize(mean=mean, std=std),\n",
        "                          ]),\n",
        "                      )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=4, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "ROqe7X5Llr2O",
        "outputId": "0beca07c-a75b-4f06-9930-7a3adecb2b7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.segmentation.deeplabv3 import deeplabv3_resnet101, DeepLabHead, FCNHead\n",
        "from torch import nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.convblock = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding='same'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.convblock(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, num_classes=7, in_channels=3, init_channels=16):\n",
        "        super(UNet, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder1 = ConvBlock(in_channels, init_channels) # (3, H, W) -> (64, H, W)\n",
        "        self.pooling1 = nn.MaxPool2d(2)\n",
        "        self.encoder2 = ConvBlock(init_channels, init_channels*2) # (64, H/2, W/2) -> (128, H/2, W/2)\n",
        "        self.pooling2 = nn.MaxPool2d(2)\n",
        "        self.encoder3 = ConvBlock(init_channels*2, init_channels*4) # (128, H/4, W/4) -> (256, H/4, W/4)\n",
        "        self.pooling3 = nn.MaxPool2d(2)\n",
        "        self.encoder4 = ConvBlock(init_channels*4, init_channels*8) # (256, H/8, W/8) -> (512, H/8, W/8)\n",
        "        self.pooling4 = nn.MaxPool2d(2)\n",
        "        self.encoder5 = ConvBlock(init_channels*8, init_channels*16) # (256, H/8, W/8) -> (512, H/8, W/8)\n",
        "        self.pooling5 = nn.MaxPool2d(2)\n",
        "        self.encoder6 = ConvBlock(init_channels*16, init_channels*32) # (512, H/16, W/16) -> (1024, H/16, W/16)\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv5 = nn.ConvTranspose2d(init_channels*32, init_channels*16, kernel_size=2, stride=2) # (1024, H/16, W/16) -> (512, H/8, W/8)\n",
        "        self.decoder5 = ConvBlock(init_channels*32, init_channels*16)\n",
        "        self.upconv4 = nn.ConvTranspose2d(init_channels*16, init_channels*8, kernel_size=2, stride=2) # (1024, H/16, W/16) -> (512, H/8, W/8)\n",
        "        self.decoder4 = ConvBlock(init_channels*16, init_channels*8)\n",
        "        self.upconv3 = nn.ConvTranspose2d(init_channels*8, init_channels*4, kernel_size=2, stride=2) # (512, H/8, W/8) -> (256, H/4, W/4)\n",
        "        self.decoder3 = ConvBlock(init_channels*8, init_channels*4)\n",
        "        self.upconv2 = nn.ConvTranspose2d(init_channels*4, init_channels*2, kernel_size=2, stride=2) # (256, H/4, W/4) -> (128, H/2, W/2)\n",
        "        self.decoder2 = ConvBlock(init_channels*4, init_channels*2)\n",
        "        self.upconv1 = nn.ConvTranspose2d(init_channels*2, init_channels, kernel_size=2, stride=2) # (128, H/2, W/2) -> (64, H, W)\n",
        "        self.decoder1 = ConvBlock(init_channels*2, init_channels)\n",
        "\n",
        "        # Output\n",
        "        self.output = nn.Conv2d(init_channels, out_channels=num_classes, kernel_size=1) # (64, H, W) -> (num_classes, H, W)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # Encoder\n",
        "        encode1 = self.encoder1(x)\n",
        "        encode2 = self.encoder2(self.pooling1(encode1))\n",
        "        encode3 = self.encoder3(self.pooling2(encode2))\n",
        "        encode4 = self.encoder4(self.pooling3(encode3))\n",
        "        encode5 = self.encoder5(self.pooling4(encode4))\n",
        "        bottleneck = self.encoder6(self.pooling5(encode5))\n",
        "\n",
        "        # Decoder\n",
        "        x = torch.cat((self.upconv5(bottleneck), encode5), dim=1) # (1024, H/8, W/8)\n",
        "        x = self.decoder5(x) # (512, H/8, W/8)\n",
        "        x = torch.cat((self.upconv4(x), encode4), dim=1) # (1024, H/8, W/8)\n",
        "        x = self.decoder4(x) # (512, H/8, W/8)\n",
        "        x = torch.cat((self.upconv3(x), encode3), dim=1) # (512, H/4, W/4)\n",
        "        x = self.decoder3(x) # (256, H/4, W/4)\n",
        "        x = torch.cat((self.upconv2(x), encode2), dim=1) # (512, H/2, W/2)\n",
        "        x = self.decoder2(x) # (128, H/4, W/4)\n",
        "        x = torch.cat((self.upconv1(x), encode1), dim=1) # (128, H, W)\n",
        "        x = self.decoder1(x) # (64, H, W)\n",
        "        x = self.output(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def get_model(path):\n",
        "    model = UNet()\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "f4Oes2rAlCxy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "\n",
        "def predimg(preds, names, out_path):\n",
        "    for pred, name in zip(preds, names):\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        pred_img = np.zeros((512, 512, 3), dtype=np.uint8)\n",
        "        pred_img[np.where(pred == 0)] = [0, 255, 255]\n",
        "        pred_img[np.where(pred == 1)] = [255, 255, 0]\n",
        "        pred_img[np.where(pred == 2)] = [255, 0, 255]\n",
        "        pred_img[np.where(pred == 3)] = [0, 255, 0]\n",
        "        pred_img[np.where(pred == 4)] = [0, 0, 255]\n",
        "        pred_img[np.where(pred == 5)] = [255, 255, 255]\n",
        "        pred_img[np.where(pred == 6)] = [0, 0, 0]\n",
        "        new_name = name.replace('sat', 'mask').replace('.jpg', '.png')\n",
        "        imageio.imwrite(os.path.join(out_path, new_name), pred_img)"
      ],
      "metadata": {
        "id": "oP5BL2V5ml9f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_1 = get_model('/content/drive/MyDrive/NTU_DLCV/p3_data/UNet_result/epoch1model.pth')\n",
        "epoch_40 = get_model('/content/drive/MyDrive/NTU_DLCV/p3_data/UNet_result/epoch40model.pth')\n",
        "epoch_80 = get_model('/content/drive/MyDrive/NTU_DLCV/p3_data/UNet_result/BestIOU.pth')\n",
        "\n",
        "output_directorys = ['/content/drive/MyDrive/NTU_DLCV/p3_data/train_plot/first/',\n",
        "                    '/content/drive/MyDrive/NTU_DLCV/p3_data/train_plot/mid/',\n",
        "                    '/content/drive/MyDrive/NTU_DLCV/p3_data/train_plot/last/']"
      ],
      "metadata": {
        "id": "NFCTbsc5Yqz-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model, output_directory in zip([epoch_1, epoch_40, epoch_80], output_directorys):\n",
        "    try:\n",
        "        os.makedirs(output_directory, exist_ok=True)\n",
        "    except:\n",
        "        pass\n",
        "    for x, filenames in test_loader:\n",
        "        with torch.no_grad():\n",
        "            x = x.to(device)\n",
        "            pred_out = model(x)\n",
        "        pred_out = pred_out.argmax(dim=1)\n",
        "        predimg(pred_out, filenames, output_directory)"
      ],
      "metadata": {
        "id": "LxmJFTHKYYOd"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}