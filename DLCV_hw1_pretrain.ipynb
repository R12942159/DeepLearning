{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/DeepLearning/blob/main/DLCV_hw1_pretrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP5MX9IGIISl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "# Get cuda from GPU device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")"
      ],
      "metadata": {
        "id": "HXjpM3inMeLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search file paths\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "img_paths_train = sorted(glob('/content/drive/MyDrive/NTU_DLCV/p1_data/train_50/*.png')) # *: all\n",
        "img_paths_val = sorted(glob('/content/drive/MyDrive/NTU_DLCV/p1_data/val_50/*.png'))"
      ],
      "metadata": {
        "id": "BK7QoEV7MewD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of images\n",
        "len(img_paths_train), len(img_paths_val)"
      ],
      "metadata": {
        "id": "dLMWfO5xMjrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_paths, img_size):\n",
        "        self.img_paths = img_paths\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"number of samples\"\"\"\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"read 1 sample\"\"\"\n",
        "        # Read img\n",
        "        path = self.img_paths[idx] # get img path\n",
        "        img = cv2.imread(path) # read img\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
        "        img = cv2.resize(img, (self.img_size, self.img_size)) # Resize iamge\n",
        "        img = img / 255.0 # 0~255 -> 0.~1.\n",
        "\n",
        "        # Read class index\n",
        "        cls_idx = int((path.split('/')[-1]).split('_')[0])\n",
        "\n",
        "        # transform img to tensor\n",
        "        img = torch.tensor(img, dtype=torch.float)\n",
        "        img = img.permute(2, 0, 1) # (H, W, C) -> (C, H, W)\n",
        "        cls_idx = torch.tensor(cls_idx, dtype=torch.long)\n",
        "\n",
        "        return img, cls_idx"
      ],
      "metadata": {
        "id": "5inTy98yMnTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build dataset\n",
        "IMG_SIZE = 32\n",
        "train_ds = MyDataset(img_paths_train, IMG_SIZE)\n",
        "val_ds = MyDataset(img_paths_val, IMG_SIZE)"
      ],
      "metadata": {
        "id": "xZ-vyEE2Mqzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build DataLoaders\n",
        "BATCH_SIZE = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, BATCH_SIZE, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_ds, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "stK3tUstMrRH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}