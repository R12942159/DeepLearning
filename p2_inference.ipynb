{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/NTU_DLCV/blob/Hw3/p2_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!gdown 1SUiRrG6zQVtyrVSVh9hOBq5_fX-oV2Lh -O hw3_data.zip # 11rP6KmR5Qwjhx0rfag0b5TZGBTRuPtQR\n",
        "!unzip /content/hw3_data.zip\n",
        "!rm hw3_data.zip"
      ],
      "metadata": {
        "id": "qp-WCQ04LBbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import timm; timm.create_model('vit_large_patch16_224.augreg_in21k', pretrained=True)\""
      ],
      "metadata": {
        "id": "rKHOGuPFR1EK",
        "outputId": "0c1bc494-2c79-4db3-80cc-15e6652bf51b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.safetensors: 100% 1.30G/1.30G [00:05<00:00, 239MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "m = timm.create_model('vit_large_patch16_224.augreg_in21k', pretrained=True)"
      ],
      "metadata": {
        "id": "Gz9z3RxTVXdn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Remove"
      ],
      "metadata": {
        "id": "dFNZRVfaR1ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import timm\n",
        "import json\n",
        "import torch\n",
        "import argparse\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as tr\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from torch import nn, Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms.functional import resize"
      ],
      "metadata": {
        "id": "BVhMTATlLcoD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### load model weights"
      ],
      "metadata": {
        "id": "T3ULd3iIh8Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1-4CZb36TCfmtLJlxz06eoy-fknC0DcZb -O large_laion_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_ENijHeh_7D",
        "outputId": "70f9d16d-0bcc-42c4-dfcb-153a715b2378"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-4CZb36TCfmtLJlxz06eoy-fknC0DcZb\n",
            "To: /content/large_laion_weights\n",
            "100% 123M/123M [00:00<00:00, 150MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument(\"path1\")\n",
        "# parser.add_argument(\"path2\")\n",
        "# parser.add_argument(\"path3\")\n",
        "# args = parser.parse_args()\n",
        "\n",
        "# img_path = args.path1\n",
        "# output_json = args.path2\n",
        "# decoder_weights = args.path3\n",
        "encoder_joson_path = './encoder.json'\n",
        "vocab_bpe_path = './vocab.bpe'\n",
        "large_laion_weights = './large_laion_weights'\n",
        "\n",
        "img_path = '/content/hw3_data/p2_data/images/val'\n",
        "output_json = '/content/pred.json'\n",
        "decoder_weights = '/content/hw3_data/p2_data/decoder_model.bin'"
      ],
      "metadata": {
        "id": "ZE6YD1SbLLzQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eg4VzCElm83",
        "outputId": "17c8ebe8-1b01-47a0-c7e7-f73423727d60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizer ('<|endoftext|>', 50256) -> 250dim"
      ],
      "metadata": {
        "id": "sIMyluP4OcRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BPETokenizer:\n",
        "\n",
        "    def __init__(self, encoder_file, vocab_file):\n",
        "        with open(encoder_file, 'r', encoding='utf-8') as f:\n",
        "            self.encoder = json.load(f)\n",
        "        self.decoder = {v:k for k,v in self.encoder.items()}\n",
        "        with open(vocab_file, 'r', encoding='utf-8') as f:\n",
        "            vocab = f.read().split('\\n')[1:-1]\n",
        "        self.bpe_ranks = {tuple(line.split()): i for i, line in enumerate(vocab)}\n",
        "        assert len(self.encoder) == 50257 and len(self.bpe_ranks) == 50000\n",
        "        bs = list(range(33, 127)) + list(range(161, 256))\n",
        "        xs = list(range(0, 33)) + list(range(127, 161))\n",
        "        cs = bs[:] + [2**8 + i for i in range(len(xs))]\n",
        "        self.byte_encoder = dict(zip(bs + xs, [chr(n) for n in cs]))\n",
        "        self.byte_decoder = {v:k for k, v in self.byte_encoder.items()}\n",
        "\n",
        "    def encode(self, text, allowed_special=None):\n",
        "        tokens = re.findall(r\"\"\"<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d| ?\"\"\" +\n",
        "                            r\"\"\"\\w+| ?\\d+| ?[^\\s\\w\\d]+|\\s+(?!\\S)|\\s+\"\"\", text, re.UNICODE)\n",
        "        def translate(token):\n",
        "            if token == '<|endoftext|>':\n",
        "                assert allowed_special and token in allowed_special\n",
        "                return [token]\n",
        "            word = tuple(''.join(self.byte_encoder[byte] for byte in token.encode('utf-8')))\n",
        "            while len(word) != 1:\n",
        "                pairs = set((word[i], word[i+1]) for i in range(len(word)-1))\n",
        "                bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
        "                if bigram not in self.bpe_ranks:\n",
        "                    break\n",
        "                a, b = bigram\n",
        "                new_word = []\n",
        "                i = 0\n",
        "                while i < len(word):\n",
        "                    j = word.index(a, i) if a in word[i:] else len(word)\n",
        "                    new_word.extend(word[i:j])\n",
        "                    i = j\n",
        "                    if i < len(word):\n",
        "                        j = 2 if i < len(word)-1 and word[i] == a and word[i+1] == b else 1\n",
        "                        new_word.append(a+b if j == 2 else word[i])\n",
        "                        i += j\n",
        "                word = tuple(new_word)\n",
        "            return word\n",
        "        return [self.encoder[_] for token in tokens for _ in translate(token)]\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        tokens = [self.decoder[token] for token in tokens]\n",
        "        buffer = bytearray([self.byte_decoder[c] for c in ''.join(tokens)])\n",
        "        return buffer.decode('utf-8', errors='replace')"
      ],
      "metadata": {
        "id": "gjc6poP1OdBM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = BPETokenizer(encoder_joson_path, vocab_bpe_path)"
      ],
      "metadata": {
        "id": "6aeCuLyJOmhP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define function"
      ],
      "metadata": {
        "id": "L0JYrzNqE0mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def json_load(json_path: str):\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    return data"
      ],
      "metadata": {
        "id": "z5xRsOP3h96o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caption_with_id(json_path: str) -> list:\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        json_data = json.load(file)\n",
        "    data = [{'caption': row['caption'], 'image_id': row['image_id']} for row in json_data['annotations']]\n",
        "    return data"
      ],
      "metadata": {
        "id": "vVR-onWwmbCI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id2file_name(json_path: str) -> dict:\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        json_data = json.load(file)\n",
        "    data = {row['id']: row['file_name'] for row in json_data['images']}\n",
        "    return data"
      ],
      "metadata": {
        "id": "rWW6y2Q1o_t-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Dataset"
      ],
      "metadata": {
        "id": "7TWHXZgugWOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImgDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root: str, transform) -> None:\n",
        "        self.transform = transform\n",
        "        self.img_path = [i for i in Path(root).glob(\"*.jpg\")]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.img_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.img_path[idx]).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        return img, os.path.splitext(self.img_path[idx].name)[0]"
      ],
      "metadata": {
        "id": "lYoLLeI3gZvS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Dataloader"
      ],
      "metadata": {
        "id": "vMk7sUiwHEPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_ds = ImgDataset(\n",
        "    root=img_path,\n",
        "    transform=tr.Compose([\n",
        "        tr.Resize(224),\n",
        "        tr.CenterCrop(224),\n",
        "        tr.ToTensor(),\n",
        "        tr.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        ")\n",
        "\n",
        "img_loader = DataLoader(\n",
        "    img_ds,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        ")"
      ],
      "metadata": {
        "id": "MMGD07vrHGiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d392b776-23c9-4a70-8624-a8384122c2f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Config"
      ],
      "metadata": {
        "id": "Fx9an6CwEx-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "\n",
        "    def __init__(self, checkpoint=None):\n",
        "        self.n_layer = 12\n",
        "        self.n_head = 12\n",
        "        self.n_embd = 768\n",
        "        self.vocab_size = 50257\n",
        "        self.block_size = 1024\n",
        "        self.checkpoint = checkpoint"
      ],
      "metadata": {
        "id": "x39qAcvyEzgi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = Config(checkpoint=decoder_weights)"
      ],
      "metadata": {
        "id": "lLwivdnDE5eq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### decoder"
      ],
      "metadata": {
        "id": "w1QQ3sdc8GRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.c_attn = nn.Linear(cfg.n_embd, 3 * cfg.n_embd)\n",
        "        self.c_proj = nn.Linear(cfg.n_embd, cfg.n_embd)\n",
        "        self.n_head = cfg.n_head\n",
        "        self.n_embd = cfg.n_embd\n",
        "        size = cfg.block_size\n",
        "        self.register_buffer('bias', torch.tril(torch.ones(size, size)).view(1, 1, size, size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch, context, embedding\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        return self.c_proj((att @ v).transpose(1, 2).contiguous().view(B, T, C))\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.multihead_attn = nn.MultiheadAttention(cfg.n_embd, cfg.n_head, batch_first=True)\n",
        "\n",
        "    def forward(self, query, encoder_out):\n",
        "        \"\"\"\n",
        "        Q is the source from the decoder, K, V are the sources from the encoder.\n",
        "        Q: (N, L, Eq), where L is the target embedding dim, Eq is embed_dim and batch_first=True.\n",
        "        {K, V}: (N, L, E{k,v}), where L is the source embedding dim, E{k,v} is {k,v}_dim and batch_first=True.\n",
        "        \"\"\"\n",
        "        attn_output, weights = self.multihead_attn(query, encoder_out, encoder_out)\n",
        "        return attn_output\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(cfg.n_embd)\n",
        "        self.ln_2 = nn.LayerNorm(cfg.n_embd)\n",
        "        self.ln_3 = nn.LayerNorm(cfg.n_embd) # add\n",
        "        self.attn = Attention(cfg)\n",
        "        self.crs_attn = CrossAttention(cfg) # add\n",
        "        self.mlp = nn.Sequential(collections.OrderedDict([\n",
        "            ('c_fc', nn.Linear(cfg.n_embd, 4 * cfg.n_embd)),\n",
        "            ('act', nn.GELU(approximate='tanh')),\n",
        "            ('c_proj', nn.Linear(4 * cfg.n_embd, cfg.n_embd))\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x, encoder_out) -> Tensor: # add\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.crs_attn(self.ln_3(x), encoder_out) # add\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.block_size = cfg.block_size\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(cfg.vocab_size, cfg.n_embd), # 文字投影\n",
        "            wpe = nn.Embedding(cfg.block_size, cfg.n_embd), # position\n",
        "            h = nn.Sequential(*[Block(cfg) for _ in range(cfg.n_layer)]), # Nx\n",
        "            ln_f = nn.LayerNorm(cfg.n_embd)\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(cfg.n_embd, cfg.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "        # timm's ViT encoder\n",
        "        self.encoder = timm.create_model('vit_large_patch14_224_clip_laion2b', pretrained=True)\n",
        "        self.linear = nn.Linear(1024, cfg.n_embd) # [16, 197, 1024]\n",
        "        # load checkpoint\n",
        "        if self.cfg.checkpoint is not None:\n",
        "            state_dict = torch.load(self.cfg.checkpoint)\n",
        "            transposed = [ '.c_attn.weight', '.c_fc.weight', '.c_proj.weight' ]\n",
        "            for key, value in state_dict.items():\n",
        "                if any(key.endswith(w) for w in transposed):\n",
        "                    state_dict[key] = value.t()\n",
        "            self.transformer.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    def forward(self, x: Tensor, img: Tensor) -> Tensor: # add\n",
        "        x = torch.narrow(x, 1, 0, min(x.size(1), self.block_size))\n",
        "        pos = torch.arange(x.size()[1], dtype=torch.long, device=x.device).unsqueeze(0)\n",
        "        x = self.transformer.wte(x) + self.transformer.wpe(pos)\n",
        "        # encoder veatures\n",
        "        encoder_out = self.encoder.forward_features(img)\n",
        "        encoder_out = self.linear(encoder_out)\n",
        "\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x, encoder_out)\n",
        "        x = self.lm_head(self.transformer.ln_f(x)) # add\n",
        "        return x"
      ],
      "metadata": {
        "id": "TYyI157L8JB7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization of Attention in Image Captioning"
      ],
      "metadata": {
        "id": "K4qEtiUZcjqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Decoder(cfg).to(device)\n",
        "model.load_state_dict(torch.load(large_laion_weights, map_location=device), strict=False)"
      ],
      "metadata": {
        "id": "2e0KXMqQhCPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_dict = {}\n",
        "for img, file_name in img_loader:\n",
        "\n",
        "    img = img.to(device)\n",
        "    start_token = torch.tensor([[50256]]).to(device)\n",
        "\n",
        "    for i in range(250):\n",
        "        with torch.no_grad():\n",
        "            pred = model(start_token, img)\n",
        "        out_token = pred.argmax(dim=2)[0][-1]\n",
        "        start_token = torch.cat((start_token, out_token.unsqueeze(0).unsqueeze(0)), dim=1)\n",
        "        end_token = torch.sum(start_token[0] == 50256).item()\n",
        "        if end_token == 2:\n",
        "            pred_token = start_token[start_token != 50256]\n",
        "            pred_token = pred_token.tolist()\n",
        "            pred_caption = encoding.decode(pred_token)\n",
        "            break\n",
        "    evaluation_dict[file_name[0]] = pred_caption\n",
        "    print('\\n', 'file name: ', file_name[0], '\\caption: ', evaluation_dict[file_name[0]])"
      ],
      "metadata": {
        "id": "UNewXUlkhKcG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "458c4b1b-8085-4cce-f701-7cc9e5a3a076"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " file name:  000000406326 \\caption:  a large mural wall with a large window, a large window, and a large window.\n",
            "\n",
            " file name:  000000383605 \\caption:   a baseball player wearing a black shirt and a black tie is in his hand .\n",
            "\n",
            " file name:  000000537289 \\caption:  a crowd of people in a small room.\n",
            "\n",
            " file name:  000000361376 \\caption:  a crowd of people in a small room.\n",
            "\n",
            " file name:  4414596147 \\caption:   a man in a red jacket and a red shirt is riding a horse that is being painted with a red cross .\n",
            "\n",
            " file name:  000000351141 \\caption:   a baseball player is being a good look at the time .\n",
            "\n",
            " file name:  000000441054 \\caption:   a brown bear with a long, dark brown beard is hanging out from the side of his face .\n",
            "\n",
            " file name:  000000149572 \\caption:   a young man is a man\n",
            "\n",
            " file name:  000000114229 \\caption:   a man in a tino shirt and a tattoo with a fake face and a fake face .\n",
            "\n",
            " file name:  000000489798 \\caption:  the man is wearing a long-sleeve shirt and a long-sleeve hat.\n",
            "\n",
            " file name:  000000170562 \\caption:   a man in a uniform uniform is riding a motorcycle .\n",
            "\n",
            " file name:  000000091636 \\caption:   a man in a suit and a black suit is wearing a black suit and a black suit .\n",
            "\n",
            " file name:  000000501923 \\caption:   a person is being attacked by a person in a violent act .\n",
            "\n",
            " file name:  000000506659 \\caption:  a young man is on the back of an elephant.\n",
            "\n",
            " file name:  000000436508 \\caption:  a beautiful looking glass door with a large glass door with a large glass door.\n",
            "\n",
            " file name:  000000469762 \\caption:  a beautiful looking glass door with a large glass door with a large glass door.\n",
            "\n",
            " file name:  3252065328 \\caption:   a man is in a bad mood .\n",
            "\n",
            " file name:  000000469130 \\caption:   a large number of blue colored paint is used to paint the exterior of the building.\n",
            "\n",
            " file name:  2462153092 \\caption:   a large number of blue colored paint is used to paint the exterior of the building.\n",
            "\n",
            " file name:  000000347267 \\caption:  the piece of art is embellished with rose and lime lime lime.\n",
            "\n",
            " file name:  000000156282 \\caption:  the piece of art is embellished with rose and lime lime lime.\n",
            "\n",
            " file name:  000000480223 \\caption:  the piece of art is embellished with rose and lime lime lime.\n",
            "\n",
            " file name:  4871416563 \\caption:  a man with a large tattoo of a woman's neck.\n",
            "\n",
            " file name:  000000313345 \\caption:   a large, well-shaped piece of fabric with a large, dark color.\n",
            "\n",
            " file name:  000000024454 \\caption:   a man is riding a surfboard in the ocean .\n",
            "\n",
            " file name:  000000529689 \\caption:  the image of a large building with a large amount of water on it.\n",
            "\n",
            " file name:  000000503275 \\caption:   a man with a beard and a man with a long shirt with a long shirt and a long shirt .\n",
            "\n",
            " file name:  000000182736 \\caption:   a man is talking on a wall in a building with a large clock on the wall .\n",
            "\n",
            " file name:  000000069501 \\caption:   a man in a black shirt is posing for a photo .\n",
            "\n",
            " file name:  335047362 \\caption:   a man in a green shirt is talking to a woman in a store .\n",
            "\n",
            " file name:  000000056193 \\caption:   a man in a green shirt is talking to a woman in a store .\n",
            "\n",
            " file name:  000000415201 \\caption:   a man in a green shirt is talking to a woman in a store .\n",
            "\n",
            " file name:  000000205689 \\caption:  a man holding a picture of a man in a bed bed.\n",
            "\n",
            " file name:  3217893350 \\caption:   a man and a young man are sitting on the beach in front of a building .\n",
            "\n",
            " file name:  000000053665 \\caption:   a person is being attacked by a person with a large, large, or large fire .\n",
            "\n",
            " file name:  000000309100 \\caption:  the image is of a zebra and girder image.\n",
            "\n",
            " file name:  000000302489 \\caption:  a group of people sitting in a room with a umbrella.\n",
            "\n",
            " file name:  000000170980 \\caption:  the tattered and hung with a picture of the thai-having.\n",
            "\n",
            " file name:  000000470114 \\caption:  the large red truck is driving a large red truck.\n",
            "\n",
            " file name:  000000549459 \\caption:  a picture of a mural with a large mural of the same name.\n",
            "\n",
            " file name:  000000425522 \\caption:  lkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkp.\n",
            "\n",
            " file name:  000000209292 \\caption:  lkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkp.\n",
            "\n",
            " file name:  247637795 \\caption:  lkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkp.\n",
            "\n",
            " file name:  2535619827 \\caption:  lkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkpkp.\n",
            "\n",
            " file name:  000000477782 \\caption:   a young man is swinging at a baseball game .\n",
            "\n",
            " file name:  000000049068 \\caption:  a young man wearing a hat and a hat is riding a horse.\n",
            "\n",
            " file name:  000000243845 \\caption:   a man and a woman are in the middle of a fire-filled street scene .\n",
            "\n",
            " file name:  2470493181 \\caption:   a young boy in a shirt-necking is hanging on a wall in the living room .\n",
            "\n",
            " file name:  000000293304 \\caption:  a small photo of a small shop with a large sign.\n",
            "\n",
            " file name:  2444070322 \\caption:  a small photo of a small shop with a large sign.\n",
            "\n",
            " file name:  000000162855 \\caption:   a young man is in a good moody moody moody moody moody moody moody moody moody .\n",
            "\n",
            " file name:  000000481891 \\caption:   a group of young boys are playing a game in a soccer game .\n",
            "\n",
            " file name:  000000243153 \\caption:  the picture is of a young man holding a tennis shirt.\n",
            "\n",
            " file name:  4505012194 \\caption:  the picture is of a young man holding a tennis shirt.\n",
            "\n",
            " file name:  000000435187 \\caption:   a man in a business suit is working on a project .\n",
            "\n",
            " file name:  6214447 \\caption:   a group of people is working with a foundation .\n",
            "\n",
            " file name:  000000062622 \\caption:   a man in a suit and a hat is standing in the sand with a large kite in her hand and a large kite in her hand .\n",
            "\n",
            " file name:  000000196777 \\caption:  a group of people sitting on a motorway.\n",
            "\n",
            " file name:  000000552579 \\caption:  a group of people sitting on a motorway.\n",
            "\n",
            " file name:  000000006393 \\caption:  a close up of a flower with a large rose on it.\n",
            "\n",
            " file name:  000000512634 \\caption:  the young man is having a lot of it in the room.\n",
            "\n",
            " file name:  1463864223 \\caption:  the young man is having a lot of it in the room.\n",
            "\n",
            " file name:  6167795092 \\caption:  the young man is having a lot of it in the room.\n",
            "\n",
            " file name:  000000452297 \\caption:  a picture of a piece of paper that is covered in a large piece of paper.\n",
            "\n",
            " file name:  000000033721 \\caption:  a young man is riding a skateboard up the side of a wall.\n",
            "\n",
            " file name:  000000237394 \\caption:  the horse is eating in a large and large-sized trough.\n",
            "\n",
            " file name:  000000357402 \\caption:  a man in a red shirt and a red tie is holding a tennis racket.\n",
            "\n",
            " file name:  000000290110 \\caption:  a fire truck is parked in a parking lot.\n",
            "\n",
            " file name:  3184738462 \\caption:   a man in a suit coat stands in front of a painting .\n",
            "\n",
            " file name:  000000549932 \\caption:   a group of people in a store is standing outside a building with a large number of books in front of it .\n",
            "\n",
            " file name:  1680126311 \\caption:   a young boy is in a photo with a picture of a fire .\n",
            "\n",
            " file name:  000000182658 \\caption:  a bathroom with a toilet paper and a toilet paper in the bathroom.\n",
            "\n",
            " file name:  000000289263 \\caption:  a young man standing on the sand of the sand of the ocean.\n",
            "\n",
            " file name:  000000335967 \\caption:  a young man standing on the sand of the sand of the ocean.\n",
            "\n",
            " file name:  2806694193 \\caption:   a man in a t-shirt is jumping off a railing .\n",
            "\n",
            " file name:  000000266041 \\caption:   a man with a black t-shirt and a baseball cap is holding a baseball game .\n",
            "\n",
            " file name:  000000249720 \\caption:   a man with a black t-shirt and a baseball cap is holding a baseball game .\n",
            "\n",
            " file name:  000000104956 \\caption:   a man with a black t-shirt and a baseball cap is holding a baseball game .\n",
            "\n",
            " file name:  708860480 \\caption:   a young boy with a long beard and a long beard .\n",
            "\n",
            " file name:  000000447726 \\caption:  a red and blue tiki mural.\n",
            "\n",
            " file name:  000000066191 \\caption:   a man in a white shirt is holding a baseball bat .\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-b7ec10bc4f30>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mout_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstart_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mend_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m50256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend_token\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mpred_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_token\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m50256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_string = json.dumps(evaluation_dict, indent=2)\n",
        "with open(output_json, 'w') as json_file:\n",
        "    json_file.write(json_string)"
      ],
      "metadata": {
        "id": "JM0VW9s3Mt8V"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}