{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/NTU_DLCV/blob/Hw2/p2_DDIM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as tr\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "import math\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "139SnVqXqy6C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-m8GI4dOVJN",
        "outputId": "c8f276e3-a7fa-46df-f9b7-91bf5888285d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gsutil\n",
        "!gsutil cp /content/drive/MyDrive/NTU_DLCV/Hw2/hw2_data.zip /content/hw2_data.zip"
      ],
      "metadata": {
        "id": "sWg2FakTOZdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/hw2_data.zip"
      ],
      "metadata": {
        "id": "9H3l8O-9Oecc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoICoHcXqvLr",
        "outputId": "136a012a-1c2b-40b3-eca8-f47076a8531f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SOGsInhcc6co"
      },
      "outputs": [],
      "source": [
        "swish = F.silu\n",
        "\n",
        "@torch.no_grad()\n",
        "def variance_scaling_init_(tensor, scale=1, mode=\"fan_avg\", distribution=\"uniform\"):\n",
        "    fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(tensor)\n",
        "\n",
        "    if mode == \"fan_in\":\n",
        "        scale /= fan_in\n",
        "\n",
        "    elif mode == \"fan_out\":\n",
        "        scale /= fan_out\n",
        "\n",
        "    else:\n",
        "        scale /= (fan_in + fan_out) / 2\n",
        "\n",
        "    if distribution == \"normal\":\n",
        "        std = math.sqrt(scale)\n",
        "\n",
        "        return tensor.normal_(0, std)\n",
        "\n",
        "    else:\n",
        "        bound = math.sqrt(3 * scale)\n",
        "\n",
        "        return tensor.uniform_(-bound, bound)\n",
        "\n",
        "\n",
        "def conv2d(\n",
        "    in_channel,\n",
        "    out_channel,\n",
        "    kernel_size,\n",
        "    stride=1,\n",
        "    padding=0,\n",
        "    bias=True,\n",
        "    scale=1,\n",
        "    mode=\"fan_avg\",\n",
        "):\n",
        "    conv = nn.Conv2d(\n",
        "        in_channel, out_channel, kernel_size, stride=stride, padding=padding, bias=bias\n",
        "    )\n",
        "\n",
        "    variance_scaling_init_(conv.weight, scale, mode=mode)\n",
        "\n",
        "    if bias:\n",
        "        nn.init.zeros_(conv.bias)\n",
        "\n",
        "    return conv\n",
        "\n",
        "\n",
        "def linear(in_channel, out_channel, scale=1, mode=\"fan_avg\"):\n",
        "    lin = nn.Linear(in_channel, out_channel)\n",
        "\n",
        "    variance_scaling_init_(lin.weight, scale, mode=mode)\n",
        "    nn.init.zeros_(lin.bias)\n",
        "\n",
        "    return lin\n",
        "\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return swish(input)\n",
        "\n",
        "\n",
        "class Upsample(nn.Sequential):\n",
        "    def __init__(self, channel):\n",
        "        layers = [\n",
        "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
        "            conv2d(channel, channel, 3, padding=1),\n",
        "        ]\n",
        "\n",
        "        super().__init__(*layers)\n",
        "\n",
        "\n",
        "class Downsample(nn.Sequential):\n",
        "    def __init__(self, channel):\n",
        "        layers = [conv2d(channel, channel, 3, stride=2, padding=1)]\n",
        "\n",
        "        super().__init__(*layers)\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channel, out_channel, time_dim, use_affine_time=False, dropout=0\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.use_affine_time = use_affine_time\n",
        "        time_out_dim = out_channel\n",
        "        time_scale = 1\n",
        "        norm_affine = True\n",
        "\n",
        "        if self.use_affine_time:\n",
        "            time_out_dim *= 2\n",
        "            time_scale = 1e-10\n",
        "            norm_affine = False\n",
        "\n",
        "        self.norm1 = nn.GroupNorm(32, in_channel)\n",
        "        self.activation1 = Swish()\n",
        "        self.conv1 = conv2d(in_channel, out_channel, 3, padding=1)\n",
        "\n",
        "        self.time = nn.Sequential(\n",
        "            Swish(), linear(time_dim, time_out_dim, scale=time_scale)\n",
        "        )\n",
        "\n",
        "        self.norm2 = nn.GroupNorm(32, out_channel, affine=norm_affine)\n",
        "        self.activation2 = Swish()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.conv2 = conv2d(out_channel, out_channel, 3, padding=1, scale=1e-10)\n",
        "\n",
        "        if in_channel != out_channel:\n",
        "            self.skip = conv2d(in_channel, out_channel, 1)\n",
        "\n",
        "        else:\n",
        "            self.skip = None\n",
        "\n",
        "    def forward(self, input, time):\n",
        "        batch = input.shape[0]\n",
        "\n",
        "        out = self.conv1(self.activation1(self.norm1(input)))\n",
        "\n",
        "        if self.use_affine_time:\n",
        "            gamma, beta = self.time(time).view(batch, -1, 1, 1).chunk(2, dim=1)\n",
        "            out = (1 + gamma) * self.norm2(out) + beta\n",
        "\n",
        "        else:\n",
        "            out = out + self.time(time).view(batch, -1, 1, 1)\n",
        "            out = self.norm2(out)\n",
        "\n",
        "        out = self.conv2(self.dropout(self.activation2(out)))\n",
        "\n",
        "        if self.skip is not None:\n",
        "            input = self.skip(input)\n",
        "\n",
        "        return out + input\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channel, n_head=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_head = n_head\n",
        "\n",
        "        self.norm = nn.GroupNorm(32, in_channel)\n",
        "        self.qkv = conv2d(in_channel, in_channel * 3, 1)\n",
        "        self.out = conv2d(in_channel, in_channel, 1, scale=1e-10)\n",
        "\n",
        "    def forward(self, input):\n",
        "        batch, channel, height, width = input.shape\n",
        "        n_head = self.n_head\n",
        "        head_dim = channel // n_head\n",
        "\n",
        "        norm = self.norm(input)\n",
        "        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n",
        "        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n",
        "\n",
        "        attn = torch.einsum(\n",
        "            \"bnchw, bncyx -> bnhwyx\", query, key\n",
        "        ).contiguous() / math.sqrt(channel)\n",
        "        attn = attn.view(batch, n_head, height, width, -1)\n",
        "        attn = torch.softmax(attn, -1)\n",
        "        attn = attn.view(batch, n_head, height, width, height, width)\n",
        "\n",
        "        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n",
        "        out = self.out(out.view(batch, channel, height, width))\n",
        "\n",
        "        return out + input\n",
        "\n",
        "\n",
        "class TimeEmbedding(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "\n",
        "        inv_freq = torch.exp(\n",
        "            torch.arange(0, dim, 2, dtype=torch.float32) * (-math.log(10000) / dim)\n",
        "        )\n",
        "\n",
        "        self.register_buffer(\"inv_freq\", inv_freq)\n",
        "\n",
        "    def forward(self, input):\n",
        "        shape = input.shape\n",
        "        sinusoid_in = torch.ger(input.view(-1).float(), self.inv_freq)\n",
        "        pos_emb = torch.cat([sinusoid_in.sin(), sinusoid_in.cos()], dim=-1)\n",
        "        pos_emb = pos_emb.view(*shape, self.dim)\n",
        "\n",
        "        return pos_emb\n",
        "\n",
        "\n",
        "class ResBlockWithAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channel,\n",
        "        out_channel,\n",
        "        time_dim,\n",
        "        dropout,\n",
        "        use_attention=False,\n",
        "        attention_head=1,\n",
        "        use_affine_time=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.resblocks = ResBlock(\n",
        "            in_channel, out_channel, time_dim, use_affine_time, dropout\n",
        "        )\n",
        "\n",
        "        if use_attention:\n",
        "            self.attention = SelfAttention(out_channel, n_head=attention_head)\n",
        "\n",
        "        else:\n",
        "            self.attention = None\n",
        "\n",
        "    def forward(self, input, time):\n",
        "        out = self.resblocks(input, time)\n",
        "\n",
        "        if self.attention is not None:\n",
        "            out = self.attention(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def spatial_unfold(input, unfold):\n",
        "    if unfold == 1:\n",
        "        return input\n",
        "\n",
        "    batch, channel, height, width = input.shape\n",
        "    h_unfold = height * unfold\n",
        "    w_unfold = width * unfold\n",
        "\n",
        "    return (\n",
        "        input.view(batch, -1, unfold, unfold, height, width)\n",
        "        .permute(0, 1, 4, 2, 5, 3)\n",
        "        .reshape(batch, -1, h_unfold, w_unfold)\n",
        "    )\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channel = 3,\n",
        "        channel = 128,\n",
        "        attn_heads = 1,\n",
        "        use_affine_time = False,\n",
        "        dropout = 0,\n",
        "    ):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "\n",
        "        time_dim = channel * 4\n",
        "\n",
        "        self.time = nn.Sequential(\n",
        "            TimeEmbedding(channel),\n",
        "            linear(channel, time_dim),\n",
        "            Swish(),\n",
        "            linear(time_dim, time_dim),\n",
        "        )\n",
        "\n",
        "        self.down1 = conv2d(in_channel, channel, 3, padding=1)\n",
        "        self.down2 = ResBlockWithAttention(128, 128,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down3 = ResBlockWithAttention(128, 128,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down4 = Downsample(128)\n",
        "        self.down5 = ResBlockWithAttention(128, 128,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down6 = ResBlockWithAttention(128, 128,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down7 = Downsample(128)\n",
        "        self.down8 = ResBlockWithAttention(128, 256,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down9 = ResBlockWithAttention(256, 256,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down10 = Downsample(256)\n",
        "        self.down11 = ResBlockWithAttention(256, 256,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down12 = ResBlockWithAttention(256, 256,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down13 = Downsample(256)\n",
        "        self.down14 = ResBlockWithAttention(256, 512,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=True,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down15 = ResBlockWithAttention(512, 512,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=True,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down16 = Downsample(512)\n",
        "        self.down17 = ResBlockWithAttention(512, 512,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.down18 = ResBlockWithAttention(512, 512,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "\n",
        "        self.mid1 = ResBlockWithAttention(\n",
        "                    512,\n",
        "                    512,\n",
        "                    time_dim,\n",
        "                    dropout=dropout,\n",
        "                    use_attention=True,\n",
        "                    attention_head=attn_heads,\n",
        "                    use_affine_time=use_affine_time,\n",
        "                )\n",
        "        self.mid2 = ResBlockWithAttention(\n",
        "                    512,\n",
        "                    512,\n",
        "                    time_dim,\n",
        "                    dropout=dropout,\n",
        "                    use_affine_time=use_affine_time,\n",
        "                )\n",
        "\n",
        "        self.up1 = ResBlockWithAttention(1024, 512,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up2 = ResBlockWithAttention(1024, 512,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up3 = ResBlockWithAttention(1024, 512,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up4 = Upsample(512)\n",
        "        self.up5 = ResBlockWithAttention(1024, 512,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=True,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up6 = ResBlockWithAttention(1024, 512,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=True,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up7 = ResBlockWithAttention(768, 512,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=True,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up8 = Upsample(512)\n",
        "        self.up9 = ResBlockWithAttention(768, 256,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up10 = ResBlockWithAttention(512, 256,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up11 = ResBlockWithAttention(512, 256,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up12 = Upsample(256)\n",
        "        self.up13 = ResBlockWithAttention(512, 256,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up14 = ResBlockWithAttention(512, 256,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up15 = ResBlockWithAttention(384, 256,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up16 = Upsample(256)\n",
        "        self.up17 = ResBlockWithAttention(384, 128,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up18 = ResBlockWithAttention(256, 128,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up19 = ResBlockWithAttention(256, 128,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up20 = Upsample(128)\n",
        "        self.up21 = ResBlockWithAttention(256, 128,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up22 = ResBlockWithAttention(256, 128,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "        self.up23 = ResBlockWithAttention(256, 128,\n",
        "                time_dim,\n",
        "                dropout,\n",
        "                use_attention=False,\n",
        "                attention_head=attn_heads,\n",
        "                use_affine_time=use_affine_time,\n",
        "            )\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            nn.GroupNorm(32, 128),\n",
        "            Swish(),\n",
        "            conv2d(128, 3 , 3, padding=1, scale=1e-10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, time):\n",
        "        time_embed = self.time(time)\n",
        "\n",
        "        feats = []\n",
        "\n",
        "        x = self.down1(x)\n",
        "        feats.append(x)\n",
        "        x = self.down2(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down3(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down4(x)\n",
        "        feats.append(x)\n",
        "        x = self.down5(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down6(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down7(x)\n",
        "        feats.append(x)\n",
        "        x = self.down8(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down9(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down10(x)\n",
        "        feats.append(x)\n",
        "        x = self.down11(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down12(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down13(x)\n",
        "        feats.append(x)\n",
        "        x = self.down14(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down15(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down16(x)\n",
        "        feats.append(x)\n",
        "        x = self.down17(x, time_embed)\n",
        "        feats.append(x)\n",
        "        x = self.down18(x, time_embed)\n",
        "        feats.append(x)\n",
        "\n",
        "\n",
        "        x = self.mid1(x, time_embed)\n",
        "        x = self.mid2(x, time_embed)\n",
        "\n",
        "        x = self.up1(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up2(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up3(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up4(x)\n",
        "        x = self.up5(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up6(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up7(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up8(x)\n",
        "        x = self.up9(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up10(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up11(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up12(x)\n",
        "        x = self.up13(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up14(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up15(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up16(x)\n",
        "        x = self.up17(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up18(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up19(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up20(x)\n",
        "        x = self.up21(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up22(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "        x = self.up23(torch.cat((x, feats.pop()), 1), time_embed)\n",
        "\n",
        "        out = self.out(x)\n",
        "        out = spatial_unfold(out, 1)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### read noise path -> torch.tensor"
      ],
      "metadata": {
        "id": "yeo6wsGHCeiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noise_read(noise_dir: str) -> torch.tensor:\n",
        "    noise_paths = [os.path.join(noise_dir, i) for i in os.listdir(noise_dir) if i.endswith('.pt') ]\n",
        "\n",
        "    noise_imgs = []\n",
        "    for path in noise_paths:\n",
        "        noise_imgs.append(torch.load(path))\n",
        "    return torch.cat(noise_imgs)\n",
        "\n",
        "# noise_imgs = noise_read('/content/hw2_data/face/noise')\n",
        "# print(noise_imgs.shape)"
      ],
      "metadata": {
        "id": "cwW6YedXCeAV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DDIM"
      ],
      "metadata": {
        "id": "Y7ISsR-6yhuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DDIM(nn.Module):\n",
        "    def __init__(self, eta=0, sample_steps=50, noise_steps=1000, beta_start=1e-4, beta_end=2e-2, img_size=256):\n",
        "        super().__init__()\n",
        "        self.eta = eta\n",
        "        self.smaple_steps = sample_steps\n",
        "        self.img_size = img_size\n",
        "\n",
        "        t_steps = torch.arange(0, noise_steps, (noise_steps // sample_steps)).long() + 1\n",
        "        t_steps = reversed(torch.cat((torch.tensor([0], dtype=torch.long), t_steps)))\n",
        "        self.t_steps = zip(t_steps[:-1], t_steps[1:])\n",
        "\n",
        "        betas = torch.linspace(beta_start, beta_end, noise_steps, dtype=torch.long)\n",
        "        alpha = 1. - betas\n",
        "        self.alpha_hat = torch.cumprod(alpha, dim=0)\n",
        "\n",
        "    def sample(self, net, device, n=10): # , noise_dir\n",
        "        # Input dim: torch.Size([n, 3, img_size, img_size])\n",
        "        # x = noise_read(noise_dir).to(self.device)\n",
        "        x = torch.randn((n, 3, self.img_size, self.img_size)).to(device)\n",
        "\n",
        "        for i, previous_i in tqdm(self.t_steps):\n",
        "            i, previous_i = i.to(device), previous_i.to(device)\n",
        "\n",
        "            # Time step, creating a tensor of size n\n",
        "            t = (torch.ones(n) * i).long()\n",
        "            # Previous time step, creating a tensor of size n\n",
        "            previous_t = (torch.ones(n) * previous_i).long()\n",
        "            # Expand to a 4-dimensional tensor, and get the value according to the time step t\n",
        "            alpha_t = self.alpha_hat[t][:, None, None, None]\n",
        "            alpha_t.to(device)\n",
        "            alpha_prev = self.alpha_hat[previous_t][:, None, None, None]\n",
        "            alpha_prev.to(device)\n",
        "\n",
        "            if i > 1:\n",
        "                noise = torch.randn_like(x).to(device)\n",
        "            else:\n",
        "                noise = torch.zeros_like(x).to(device)\n",
        "\n",
        "            # Images and time steps input into the model\n",
        "            predicted_noise = net(x, t).to(device)\n",
        "\n",
        "            x0_t = (torch.clamp((x - (predicted_noise * torch.sqrt((1 - alpha_t)))) / torch.sqrt(alpha_t), -1, 1))\n",
        "            c1 = (self.eta * torch.sqrt((1 - alpha_t / alpha_prev) * (1 - alpha_prev) / (1 - alpha_t)))\n",
        "            c2 = (torch.sqrt((1 - alpha_prev) - c1 ** 2))\n",
        "            x = (torch.sqrt(alpha_prev) * x0_t + c2 * predicted_noise + c1 * noise)\n",
        "\n",
        "        # # Return the value to the range of 0 and 1\n",
        "        # x = ((x + 1) * 0.5)\n",
        "        # # Multiply by 255 to enter the effective pixel range\n",
        "        # x = ((x * 255).type(torch.uint8))\n",
        "        return x"
      ],
      "metadata": {
        "id": "PEQ90sv1yi0m"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = UNet()\n",
        "net.to(device)\n",
        "net.load_state_dict(torch.load('/content/hw2_data/face/UNet.pt', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z59TLI5w-oDp",
        "outputId": "5e10e30c-0dcf-4bdd-c4ec-2da1eb9918c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddim = DDIM()\n",
        "ddim.eval()\n",
        "ddim.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yflEEoa4AzO4",
        "outputId": "6796498c-38d3-4128-ce32-3cf9999fbe45"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DDIM()"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    x = ddim.sample(net, device, n=10) # '/content/hw2_data/face/noise',\n",
        "    # x_t = x_t.view(10, 3, 256, 256)\n",
        "    # x_t = torch.transpose(x_t, 0, 1).reshape(-1, 3, 28, 28)\n",
        "\n",
        "    # save_image(x_t,\n",
        "    #            f'face.png',\n",
        "    #            nrow=1)\n",
        "    # for i in range(6):\n",
        "    #     save_image(torch.tensor(x_t_store[i, 0, ...].reshape(-1, 3, 28, 28)),\n",
        "    #            f'/content/drive/MyDrive/NTU_DLCV/Hw2/p1_problem_img_{n_feature}/zero_{i}_step_{n_feature}.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "vWkj7bsQSGOt",
        "outputId": "a94b3928-4be5-444e-e57e-8264db08f402"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [14:34, 124.94s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-27767251ca54>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# '/content/hw2_data/face/noise',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# x_t = x_t.view(10, 3, 256, 256)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# x_t = torch.transpose(x_t, 0, 1).reshape(-1, 3, 28, 28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-aab01fa0b2b4>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, net, device, n)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Images and time steps input into the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mpredicted_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mx0_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_noise\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4e951d9e882e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, time)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4e951d9e882e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, time)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4e951d9e882e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, time)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_affine_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4e951d9e882e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mswish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2070\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}