{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R12942159/NTU_DLCV/blob/Final/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "jBBXV-tY1ZPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-sZEnk8wLLh"
      },
      "outputs": [],
      "source": [
        "!gdown 1GKteorlflRDTpSTVfPFFUqLcng7j5wCP -O llama.zip\n",
        "!unzip ./llama.zip\n",
        "!rm llama.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/DLCV-Fall-2023-Final-1-rats.zip\n",
        "!rm DLCV-Fall-2023-Final-1-rats.zip"
      ],
      "metadata": {
        "id": "IafRXBOOzKWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1MWPslINi3BtRpm_H6MNb7BNHdirb1lQ4 -O data.zip\n",
        "!unzip ./data.zip\n",
        "!rm data.zip"
      ],
      "metadata": {
        "id": "UC5FH9PEW0VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd DLCV-Fall-2023-Final-1-rats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY6ScqOP1K8P",
        "outputId": "6b92caa6-ce66-41ef-dec9-a87966138618"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DLCV-Fall-2023-Final-1-rats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir pretrained"
      ],
      "metadata": {
        "id": "6a8-gwmQ8YCZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir -p checkpoint/rats_w_description"
      ],
      "metadata": {
        "id": "XHxdOS5W9NpC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd checkpoint/rats_w_description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuGdW6OJIHN_",
        "outputId": "3a3c905e-ade2-4912-f3b8-a2b17b2424f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DLCV-Fall-2023-Final-1-rats/checkpoint/rats_w_description\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1VDcITcL5lsvgKr5xssDHq9hgP2auQ9YI -O checkpoint_best.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p49qLpuIAmZ",
        "outputId": "a4e6da88-a27b-4c81-df2f-0e59efcf8236"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VDcITcL5lsvgKr5xssDHq9hgP2auQ9YI\n",
            "To: /content/DLCV-Fall-2023-Final-1-rats/checkpoint/rats_w_description/checkpoint_best.pth\n",
            "100% 54.1M/54.1M [00:00<00:00, 144MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkeByNf_ICj6",
        "outputId": "38d878b8-4b66-4880-e294-e1e190def96a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DLCV-Fall-2023-Final-1-rats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash setup.sh"
      ],
      "metadata": {
        "id": "jpUF-YVc1FaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash inference.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S542GxLb1JTg",
        "outputId": "56211104-2f80-40e3-e422-413a29f6608c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "[16:03:00.288524] job dir: /content/DLCV-Fall-2023-Final-1-rats\n",
            "[16:03:00.288613] Namespace(batch_size=1,\n",
            "epochs=400,\n",
            "accum_iter=1,\n",
            "llama_model_path='./pretrained/llama/',\n",
            "model='7B',\n",
            "adapter_layer=32,\n",
            "adapter_len=10,\n",
            "max_seq_len=256,\n",
            "max_feats=10,\n",
            "dataset='star',\n",
            "output_dir='./output/rats_w_description',\n",
            "device='cuda',\n",
            "seed=0,\n",
            "resume='./checkpoint/rats_w_description/checkpoint_best.pth',\n",
            "start_epoch=0,\n",
            "num_workers=2,\n",
            "pin_mem=True,\n",
            "world_size=1,\n",
            "local_rank=-1,\n",
            "dist_on_itp=False,\n",
            "dist_url='env://',\n",
            "vaq=False,\n",
            "qav=False,\n",
            "vqd=False,\n",
            "bias=3.0,\n",
            "tau=100.0,\n",
            "sub=False,\n",
            "split='val',\n",
            "distributed=False)\n",
            "[16:03:05.150586] Num val data: 7098\n",
            "[16:03:05.163163] Using model: 7B\n",
            "[16:03:05.163539] loading from pretrained/llama/7B/consolidated.00.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DLCV-Fall-2023-Final-1-rats/inference.py\", line 181, in <module>\n",
            "    main(args)\n",
            "  File \"/content/DLCV-Fall-2023-Final-1-rats/inference.py\", line 86, in main\n",
            "    model = LLaMA_VQA(args)\n",
            "  File \"/content/DLCV-Fall-2023-Final-1-rats/llama_vqa.py\", line 58, in LLaMA_VQA\n",
            "    model_llama_vqa = Transformer(model_args, args)\n",
            "  File \"/content/DLCV-Fall-2023-Final-1-rats/llama/model.py\", line 193, in __init__\n",
            "    self.layers.append(TransformerBlock(layer_id, params))\n",
            "  File \"/content/DLCV-Fall-2023-Final-1-rats/llama/model.py\", line 150, in __init__\n",
            "    self.attention = Attention(args)\n",
            "  File \"/content/DLCV-Fall-2023-Final-1-rats/llama/model.py\", line 78, in __init__\n",
            "    self.wv = Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 96, in __init__\n",
            "    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 15.77 GiB of which 28.38 MiB is free. Process 18673 has 15.74 GiB memory in use. Of the allocated memory 15.37 GiB is allocated by PyTorch, and 12.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    }
  ]
}